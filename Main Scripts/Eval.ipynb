{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Base Scripts\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLibraries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVAE\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLibraries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUtils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mConf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\finia\\OneDrive - SBL\\MA\\MA_DDPM\\Libraries\\VAE.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mUtils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     11\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConvBottleneckEncoder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Utils'"
     ]
    }
   ],
   "source": [
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging\n",
    "# Base Scripts\n",
    "from Libraries.VAE import *\n",
    "from Libraries.Utils import *\n",
    "from Conf import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name: str = \"conv_VAE_v1\"\n",
    "training_data_name: str = \"training_v2\"\n",
    "logging_level: int = LIGHT_DEBUG\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(model: nn.Module, device: str,  n_samples: int = 1, seed: ndarray = None, file_name: str = \"test\") -> None:\n",
    "    model.eval()\n",
    "    if seed is not None:\n",
    "        save_audio_file(spectrogram_to_audio(unnormalize(seed), LEN_FFT), f\"{RESULT_PATH}/{file_name}_seed.wav\")\n",
    "        samples = generate_sample(model, device, Tensor(seed).view(1, 1, seed.shape[-2], seed.shape[-1]), num_samples=n_samples)\n",
    "    else:\n",
    "        samples = generate_sample(model, device, num_samples=n_samples)\n",
    "    for i in range(samples.shape[1]):\n",
    "        save_audio_file(spectrogram_to_audio(unnormalize(samples[0,i]), LEN_FFT), f\"{RESULT_PATH}/{file_name}_{i:02d}.wav\", SAMPLE_RATE)\n",
    "    logger.light_debug(f\"Saved {samples.shape[0]} samples to {RESULT_PATH}\")\n",
    "\n",
    "\n",
    "def pass_through(model: nn.Module, device: str, sample: ndarray, file_name: str = \"test\") -> None:\n",
    "    save_audio_file(spectrogram_to_audio(unnormalize(sample), LEN_FFT), f\"{RESULT_PATH}/{file_name}_inp.wav\")\n",
    "    x = fwd_pass(model, device, Tensor(sample).view(1, 1, sample.shape[-2], sample.shape[-1]))\n",
    "    save_audio_file(spectrogram_to_audio(unnormalize(x[0,0]), LEN_FFT), f\"{RESULT_PATH}/{file_name}_out.wav\")\n",
    "    logger.light_debug(f\"Saved passed through sample to {RESULT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading & Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = load_training_data(f\"{DATA_PATH}/{training_data_name}.npy\")\n",
    "logger.info(f\"Data loaded with shape: {file.shape}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = VAE(in_channels=1, latent_dim=128, device=device,input_shape=[0,0, file.shape[-2], file.shape[-1]], n_conv_blocks=1, n_starting_filters=32, lin_bottleneck=False).to(device)\n",
    "model.load_state_dict(torch.load(f\"{MODEL_PATH}/{model_name}.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_data(model=model, seed=file[100])\n",
    "pass_through(file[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
