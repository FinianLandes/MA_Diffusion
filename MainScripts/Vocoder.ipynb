{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0896dd2a",
   "metadata": {},
   "source": [
    "# Main Script for a Vocoder\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7059a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.3)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soxr, msgpack, llvmlite, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging, librosa\n",
    "from typing import Sequence, Optional, Callable\n",
    "\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d7fbc",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12e407",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c14554",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = True #Set to true if using a remote Kernel changes the file structure\n",
    "model_name: str = \"MelGan_v1\"\n",
    "training_data_name: str = \"training_full_mel\"\n",
    "training_label_name: str = \"training_full_wave\"\n",
    "full_model_path: str = path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, model_name + \".pth\"), remote_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7c208",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c656f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level: int = logging.INFO\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924858d",
   "metadata": {},
   "source": [
    "Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc9b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_training_samples: int = 2496 // 2\n",
    "batch_size: int = 64\n",
    "tensor_waver_dim: list = [batch_size, 1, 2**17] #B, C, H = Batch, channels, Time domain\n",
    "tensor_mel_dim: list = [batch_size, 96, 512]\n",
    "learning_rate: float = 1e-4\n",
    "epochs: int = 300\n",
    "restart_training: bool = True\n",
    "checkpoint_freq: int = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571b189",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c201a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_data: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))\n",
    "audio_data: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_label_name + \".npy\"), remote_kernel))\n",
    "\n",
    "np.random.seed(50)\n",
    "indicies: ndarray = np.arange(mel_data.shape[0])\n",
    "np.random.shuffle(indicies)\n",
    "mel_data = mel_data[indicies]\n",
    "audio_data = audio_data[indicies]\n",
    "\n",
    "\n",
    "data_loader = create_dataloader(Audio_Data(mel_data[:n_training_samples], audio_data[:n_training_samples]), batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a34ad",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d84a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mel2Wave(nn.Module):\n",
    "    def __init__(self, in_channels: int, intermediate_channels: int = 512) -> None:\n",
    "        super(Mel2Wave, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, intermediate_channels, kernel_size=7, stride=1, padding=3),\n",
    "            \n",
    "            Upsample(in_channels=intermediate_channels, out_channels=intermediate_channels // 2, factor=8),\n",
    "            ResStack(channels=intermediate_channels // 2),\n",
    "\n",
    "            Upsample(in_channels=intermediate_channels // 2, out_channels=intermediate_channels // 4, factor=8),\n",
    "            ResStack(channels=intermediate_channels // 4),\n",
    "\n",
    "            Upsample(in_channels=intermediate_channels // 4, out_channels=intermediate_channels // 8, factor=2),\n",
    "            ResStack(channels=intermediate_channels // 8),\n",
    "\n",
    "            Upsample(in_channels=intermediate_channels // 8, out_channels=intermediate_channels // 16, factor=2),\n",
    "            ResStack(channels=intermediate_channels // 16),\n",
    "\n",
    "            nn.Conv1d(intermediate_channels // 16, 1, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.block(x)\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, factor: int) -> None:\n",
    "        super(Upsample, self).__init__()\n",
    "        kernel_size = factor * 2\n",
    "        stride = factor\n",
    "        padding = factor // 2 + factor % 2\n",
    "        output_padding = factor % 2\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=output_padding),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.block(x)\n",
    "\n",
    "class DilConv(nn.Module):\n",
    "    def __init__(self, channels: int, dilation: int) -> None:\n",
    "        super(DilConv, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv1d(channels, channels, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResStack(nn.Module):\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super(ResStack, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            DilConv(channels, 1),\n",
    "            DilConv(channels, 3),\n",
    "            DilConv(channels, 9)\n",
    "        )\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.block(x)\n",
    "\n",
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int = 1, channels: int = 16) -> None:\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, channels, kernel_size=15, stride=1, padding=7),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv1d(channels, channels*4, kernel_size=41, stride=4, padding=20, groups=4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv1d(channels*4, channels*8, kernel_size=41, stride=4, padding=20, groups=16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv1d(channels*8, channels*16, kernel_size=41, stride=4, padding=20, groups=16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv1d(channels*16, channels*16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv1d(channels*16, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor,...]:\n",
    "        feature_maps = []\n",
    "        for layer in self.block:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.Conv1d):\n",
    "                feature_maps.append(x)\n",
    "        return x, feature_maps\n",
    "\n",
    "class MultiScaleDiscriminator(nn.Module):\n",
    "    def __init__(self, in_channels: int = 1, channels: int = 16) -> None:\n",
    "        super().__init__()\n",
    "        self.pooling = nn.AvgPool1d(kernel_size=4, stride=2, padding=1)\n",
    "        self.discriminators = nn.ModuleList([\n",
    "            DiscriminatorBlock(in_channels, channels),\n",
    "            DiscriminatorBlock(in_channels, channels),\n",
    "            DiscriminatorBlock(in_channels, channels),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, ...]:\n",
    "        outputs = []\n",
    "        feature_maps = []\n",
    "        for disc in self.discriminators:\n",
    "            out, fmap = disc(x)\n",
    "            outputs.append(out)\n",
    "            feature_maps.append(fmap)\n",
    "            x = self.pooling(x)\n",
    "        return outputs, feature_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ac5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Mel2Wave(in_channels=96, intermediate_channels=512).to(device)\n",
    "discriminator=MultiScaleDiscriminator(in_channels=1, channels=16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba70fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 07:41:00,127 - INFO - Model MelGan_v1 loaded with ~4.055M and ~1.335M Parameters\n"
     ]
    }
   ],
   "source": [
    "gen_optim = optim.AdamW(generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
    "disc_optim = optim.AdamW(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
    "\n",
    "start_epoch: int = 0\n",
    "if os.path.exists(full_model_path):\n",
    "    model = torch.load(full_model_path, map_location=device)\n",
    "    generator.load_state_dict(model[\"generator\"])\n",
    "    discriminator.load_state_dict(model[\"discriminator\"])\n",
    "    if not restart_training:\n",
    "        gen_optim.load_state_dict(model[\"gen_optim\"])\n",
    "        disc_optim.load_state_dict(model[\"disc_optim\"])\n",
    "        start_epoch = model.get(\"epoch\", 0)\n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(generator)} and {count_parameters(discriminator)} Parameters\")\n",
    "else: \n",
    "    logger.info(f\"Model {model_name} created with {count_parameters(generator)} and {count_parameters(discriminator)} Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2793b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = nn.MSELoss()\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "recon_loss_weight: float = 150.0\n",
    "fm_loss_weight: float = 10.0\n",
    "label_smooth_val: float = 0.1\n",
    "\n",
    "n_gen_updates: int = 2\n",
    "n_disc_updates: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fd1d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 07:51:08,749 - INFO - Training started on cuda\n",
      "2025-06-07 07:51:48,150 - INFO - Epoch 001: Avg. D/G Loss: 3.1395e-01, 5.3380e+01 Remaining Time: 03h 16min 20s LR: 1.00000e-04 \n",
      "2025-06-07 07:52:28,310 - INFO - Epoch 002: Avg. D/G Loss: 3.0397e-01, 5.2804e+01 Remaining Time: 03h 17min 34s LR: 1.00000e-04 \n",
      "2025-06-07 07:53:07,992 - INFO - Epoch 003: Avg. D/G Loss: 3.0382e-01, 5.2784e+01 Remaining Time: 03h 16min 44s LR: 1.00000e-04 \n",
      "2025-06-07 07:53:46,492 - INFO - Epoch 004: Avg. D/G Loss: 2.9763e-01, 5.2760e+01 Remaining Time: 03h 14min 32s LR: 1.00000e-04 \n",
      "2025-06-07 07:54:27,129 - INFO - Epoch 005: Avg. D/G Loss: 2.9238e-01, 5.3003e+01 Remaining Time: 03h 15min 04s LR: 1.00000e-04 \n",
      "2025-06-07 07:55:06,638 - INFO - Epoch 006: Avg. D/G Loss: 2.9623e-01, 5.2610e+01 Remaining Time: 03h 14min 11s LR: 1.00000e-04 \n",
      "2025-06-07 07:55:48,520 - INFO - Epoch 007: Avg. D/G Loss: 3.0015e-01, 5.2692e+01 Remaining Time: 03h 15min 06s LR: 1.00000e-04 \n",
      "2025-06-07 07:56:28,745 - INFO - Epoch 008: Avg. D/G Loss: 2.9856e-01, 5.2564e+01 Remaining Time: 03h 14min 36s LR: 1.00000e-04 \n",
      "2025-06-07 07:57:09,552 - INFO - Epoch 009: Avg. D/G Loss: 2.9713e-01, 5.2629e+01 Remaining Time: 03h 14min 22s LR: 1.00000e-04 \n",
      "2025-06-07 07:57:48,234 - INFO - Epoch 010: Avg. D/G Loss: 2.9244e-01, 5.2571e+01 Remaining Time: 03h 13min 02s LR: 1.00000e-04 \n",
      "2025-06-07 07:58:27,921 - INFO - Epoch 011: Avg. D/G Loss: 2.9135e-01, 5.2540e+01 Remaining Time: 03h 12min 13s LR: 1.00000e-04 \n",
      "2025-06-07 07:59:07,571 - INFO - Epoch 012: Avg. D/G Loss: 2.9622e-01, 5.2513e+01 Remaining Time: 03h 11min 27s LR: 1.00000e-04 \n",
      "2025-06-07 07:59:49,275 - INFO - Epoch 013: Avg. D/G Loss: 2.8841e-01, 5.2446e+01 Remaining Time: 03h 11min 27s LR: 1.00000e-04 \n",
      "2025-06-07 08:00:29,949 - INFO - Epoch 014: Avg. D/G Loss: 2.8953e-01, 5.2447e+01 Remaining Time: 03h 11min 00s LR: 1.00000e-04 \n",
      "2025-06-07 08:01:11,310 - INFO - Epoch 015: Avg. D/G Loss: 2.9311e-01, 5.2502e+01 Remaining Time: 03h 10min 45s LR: 1.00000e-04 \n",
      "2025-06-07 08:01:51,839 - INFO - Epoch 016: Avg. D/G Loss: 2.8812e-01, 5.2334e+01 Remaining Time: 03h 10min 10s LR: 1.00000e-04 \n",
      "2025-06-07 08:02:30,654 - INFO - Epoch 017: Avg. D/G Loss: 2.8755e-01, 5.2304e+01 Remaining Time: 03h 09min 07s LR: 1.00000e-04 \n",
      "2025-06-07 08:03:11,879 - INFO - Epoch 018: Avg. D/G Loss: 2.8902e-01, 5.2277e+01 Remaining Time: 03h 08min 44s LR: 1.00000e-04 \n",
      "2025-06-07 08:03:53,725 - INFO - Epoch 019: Avg. D/G Loss: 2.9797e-01, 5.2328e+01 Remaining Time: 03h 08min 29s LR: 1.00000e-04 \n",
      "2025-06-07 08:04:34,408 - INFO - Epoch 020: Avg. D/G Loss: 2.8816e-01, 5.2261e+01 Remaining Time: 03h 07min 55s LR: 1.00000e-04 \n",
      "2025-06-07 08:05:14,575 - INFO - Epoch 021: Avg. D/G Loss: 2.8446e-01, 5.2248e+01 Remaining Time: 03h 07min 11s LR: 1.00000e-04 \n",
      "2025-06-07 08:05:53,366 - INFO - Epoch 022: Avg. D/G Loss: 2.8495e-01, 5.2197e+01 Remaining Time: 03h 06min 12s LR: 1.00000e-04 \n",
      "2025-06-07 08:06:37,070 - INFO - Epoch 023: Avg. D/G Loss: 2.8593e-01, 5.2206e+01 Remaining Time: 03h 06min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:07:20,032 - INFO - Epoch 024: Avg. D/G Loss: 2.8820e-01, 5.2098e+01 Remaining Time: 03h 06min 04s LR: 1.00000e-04 \n",
      "2025-06-07 08:07:59,555 - INFO - Epoch 025: Avg. D/G Loss: 2.8719e-01, 5.2148e+01 Remaining Time: 03h 05min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:08:39,986 - INFO - Epoch 026: Avg. D/G Loss: 2.8364e-01, 5.2025e+01 Remaining Time: 03h 04min 32s LR: 1.00000e-04 \n",
      "2025-06-07 08:09:20,768 - INFO - Epoch 027: Avg. D/G Loss: 2.8329e-01, 5.2075e+01 Remaining Time: 03h 03min 56s LR: 1.00000e-04 \n",
      "2025-06-07 08:09:59,709 - INFO - Epoch 028: Avg. D/G Loss: 2.8688e-01, 5.1988e+01 Remaining Time: 03h 03min 01s LR: 1.00000e-04 \n",
      "2025-06-07 08:10:42,635 - INFO - Epoch 029: Avg. D/G Loss: 2.8369e-01, 5.1946e+01 Remaining Time: 03h 02min 44s LR: 1.00000e-04 \n",
      "2025-06-07 08:11:23,398 - INFO - Epoch 030: Avg. D/G Loss: 2.8190e-01, 5.1913e+01 Remaining Time: 03h 02min 06s LR: 1.00000e-04 \n",
      "2025-06-07 08:12:02,861 - INFO - Epoch 031: Avg. D/G Loss: 2.8676e-01, 5.1903e+01 Remaining Time: 03h 01min 16s LR: 1.00000e-04 \n",
      "2025-06-07 08:12:43,041 - INFO - Epoch 032: Avg. D/G Loss: 2.8663e-01, 5.1876e+01 Remaining Time: 03h 00min 34s LR: 1.00000e-04 \n",
      "2025-06-07 08:13:23,790 - INFO - Epoch 033: Avg. D/G Loss: 2.8441e-01, 5.1978e+01 Remaining Time: 02h 59min 56s LR: 1.00000e-04 \n",
      "2025-06-07 08:14:05,093 - INFO - Epoch 034: Avg. D/G Loss: 2.8149e-01, 5.1822e+01 Remaining Time: 02h 59min 22s LR: 1.00000e-04 \n",
      "2025-06-07 08:14:44,859 - INFO - Epoch 035: Avg. D/G Loss: 2.7852e-01, 5.1732e+01 Remaining Time: 02h 58min 37s LR: 1.00000e-04 \n",
      "2025-06-07 08:15:24,410 - INFO - Epoch 036: Avg. D/G Loss: 2.8426e-01, 5.1799e+01 Remaining Time: 02h 57min 49s LR: 1.00000e-04 \n",
      "2025-06-07 08:16:05,560 - INFO - Epoch 037: Avg. D/G Loss: 2.8242e-01, 5.1700e+01 Remaining Time: 02h 57min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:16:44,512 - INFO - Epoch 038: Avg. D/G Loss: 2.7607e-01, 5.1705e+01 Remaining Time: 02h 56min 23s LR: 1.00000e-04 \n",
      "2025-06-07 08:17:23,174 - INFO - Epoch 039: Avg. D/G Loss: 2.8267e-01, 5.1815e+01 Remaining Time: 02h 55min 31s LR: 1.00000e-04 \n",
      "2025-06-07 08:18:02,041 - INFO - Epoch 040: Avg. D/G Loss: 2.7947e-01, 5.1628e+01 Remaining Time: 02h 54min 41s LR: 1.00000e-04 \n",
      "2025-06-07 08:18:41,958 - INFO - Epoch 041: Avg. D/G Loss: 2.7536e-01, 5.1762e+01 Remaining Time: 02h 53min 58s LR: 1.00000e-04 \n",
      "2025-06-07 08:19:23,354 - INFO - Epoch 042: Avg. D/G Loss: 2.7916e-01, 5.1510e+01 Remaining Time: 02h 53min 24s LR: 1.00000e-04 \n",
      "2025-06-07 08:20:02,617 - INFO - Epoch 043: Avg. D/G Loss: 2.7586e-01, 5.1462e+01 Remaining Time: 02h 52min 37s LR: 1.00000e-04 \n",
      "2025-06-07 08:20:42,949 - INFO - Epoch 044: Avg. D/G Loss: 2.8024e-01, 5.1599e+01 Remaining Time: 02h 51min 57s LR: 1.00000e-04 \n",
      "2025-06-07 08:21:23,512 - INFO - Epoch 045: Avg. D/G Loss: 2.8029e-01, 5.1438e+01 Remaining Time: 02h 51min 19s LR: 1.00000e-04 \n",
      "2025-06-07 08:22:03,179 - INFO - Epoch 046: Avg. D/G Loss: 2.7507e-01, 5.1430e+01 Remaining Time: 02h 50min 34s LR: 1.00000e-04 \n",
      "2025-06-07 08:22:44,870 - INFO - Epoch 047: Avg. D/G Loss: 2.7670e-01, 5.1427e+01 Remaining Time: 02h 50min 01s LR: 1.00000e-04 \n",
      "2025-06-07 08:23:23,787 - INFO - Epoch 048: Avg. D/G Loss: 2.7530e-01, 5.1524e+01 Remaining Time: 02h 49min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:24:02,560 - INFO - Epoch 049: Avg. D/G Loss: 2.7314e-01, 5.1501e+01 Remaining Time: 02h 48min 25s LR: 1.00000e-04 \n",
      "2025-06-07 08:24:44,020 - INFO - Epoch 050: Avg. D/G Loss: 2.7060e-01, 5.1490e+01 Remaining Time: 02h 47min 51s LR: 1.00000e-04 \n",
      "2025-06-07 08:25:23,181 - INFO - Epoch 051: Avg. D/G Loss: 2.7353e-01, 5.1339e+01 Remaining Time: 02h 47min 05s LR: 1.00000e-04 \n",
      "2025-06-07 08:26:02,411 - INFO - Epoch 052: Avg. D/G Loss: 2.6970e-01, 5.1353e+01 Remaining Time: 02h 46min 20s LR: 1.00000e-04 \n",
      "2025-06-07 08:26:41,749 - INFO - Epoch 053: Avg. D/G Loss: 2.7480e-01, 5.1312e+01 Remaining Time: 02h 45min 35s LR: 1.00000e-04 \n",
      "2025-06-07 08:27:20,496 - INFO - Epoch 054: Avg. D/G Loss: 2.7134e-01, 5.1386e+01 Remaining Time: 02h 44min 48s LR: 1.00000e-04 \n",
      "2025-06-07 08:28:01,662 - INFO - Epoch 055: Avg. D/G Loss: 2.6936e-01, 5.1284e+01 Remaining Time: 02h 44min 12s LR: 1.00000e-04 \n",
      "2025-06-07 08:28:41,028 - INFO - Epoch 056: Avg. D/G Loss: 2.6688e-01, 5.1293e+01 Remaining Time: 02h 43min 28s LR: 1.00000e-04 \n",
      "2025-06-07 08:29:20,968 - INFO - Epoch 057: Avg. D/G Loss: 2.6804e-01, 5.1289e+01 Remaining Time: 02h 42min 47s LR: 1.00000e-04 \n",
      "2025-06-07 08:30:00,064 - INFO - Epoch 058: Avg. D/G Loss: 2.6534e-01, 5.1358e+01 Remaining Time: 02h 42min 02s LR: 1.00000e-04 \n",
      "2025-06-07 08:30:42,324 - INFO - Epoch 059: Avg. D/G Loss: 2.7253e-01, 5.1182e+01 Remaining Time: 02h 41min 30s LR: 1.00000e-04 \n",
      "2025-06-07 08:31:24,328 - INFO - Epoch 060: Avg. D/G Loss: 2.6540e-01, 5.1103e+01 Remaining Time: 02h 40min 57s LR: 1.00000e-04 \n",
      "2025-06-07 08:32:03,307 - INFO - Epoch 061: Avg. D/G Loss: 2.6846e-01, 5.1152e+01 Remaining Time: 02h 40min 12s LR: 1.00000e-04 \n",
      "2025-06-07 08:32:42,410 - INFO - Epoch 062: Avg. D/G Loss: 2.6638e-01, 5.1007e+01 Remaining Time: 02h 39min 27s LR: 1.00000e-04 \n",
      "2025-06-07 08:33:23,357 - INFO - Epoch 063: Avg. D/G Loss: 2.7164e-01, 5.1050e+01 Remaining Time: 02h 38min 50s LR: 1.00000e-04 \n",
      "2025-06-07 08:34:04,670 - INFO - Epoch 064: Avg. D/G Loss: 2.6470e-01, 5.0985e+01 Remaining Time: 02h 38min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:34:44,597 - INFO - Epoch 065: Avg. D/G Loss: 2.6985e-01, 5.0966e+01 Remaining Time: 02h 37min 32s LR: 1.00000e-04 \n",
      "2025-06-07 08:35:25,819 - INFO - Epoch 066: Avg. D/G Loss: 2.7043e-01, 5.0984e+01 Remaining Time: 02h 36min 55s LR: 1.00000e-04 \n",
      "2025-06-07 08:36:05,813 - INFO - Epoch 067: Avg. D/G Loss: 2.6813e-01, 5.0916e+01 Remaining Time: 02h 36min 14s LR: 1.00000e-04 \n",
      "2025-06-07 08:36:48,968 - INFO - Epoch 068: Avg. D/G Loss: 2.6812e-01, 5.0919e+01 Remaining Time: 02h 35min 44s LR: 1.00000e-04 \n",
      "2025-06-07 08:37:34,478 - INFO - Epoch 069: Avg. D/G Loss: 2.6573e-01, 5.0846e+01 Remaining Time: 02h 35min 21s LR: 1.00000e-04 \n",
      "2025-06-07 08:38:14,418 - INFO - Epoch 070: Avg. D/G Loss: 2.6598e-01, 5.0958e+01 Remaining Time: 02h 34min 40s LR: 1.00000e-04 \n",
      "2025-06-07 08:38:54,548 - INFO - Epoch 071: Avg. D/G Loss: 2.6267e-01, 5.0946e+01 Remaining Time: 02h 33min 58s LR: 1.00000e-04 \n",
      "2025-06-07 08:39:36,990 - INFO - Epoch 072: Avg. D/G Loss: 2.6501e-01, 5.0800e+01 Remaining Time: 02h 33min 25s LR: 1.00000e-04 \n",
      "2025-06-07 08:40:17,602 - INFO - Epoch 073: Avg. D/G Loss: 2.6527e-01, 5.0851e+01 Remaining Time: 02h 32min 45s LR: 1.00000e-04 \n",
      "2025-06-07 08:40:57,396 - INFO - Epoch 074: Avg. D/G Loss: 2.6511e-01, 5.0727e+01 Remaining Time: 02h 32min 03s LR: 1.00000e-04 \n",
      "2025-06-07 08:41:40,219 - INFO - Epoch 075: Avg. D/G Loss: 2.6483e-01, 5.0886e+01 Remaining Time: 02h 31min 30s LR: 1.00000e-04 \n",
      "2025-06-07 08:42:20,050 - INFO - Epoch 076: Avg. D/G Loss: 2.6650e-01, 5.0717e+01 Remaining Time: 02h 30min 47s LR: 1.00000e-04 \n",
      "2025-06-07 08:42:58,841 - INFO - Epoch 077: Avg. D/G Loss: 2.6675e-01, 5.0695e+01 Remaining Time: 02h 30min 02s LR: 1.00000e-04 \n",
      "2025-06-07 08:43:38,502 - INFO - Epoch 078: Avg. D/G Loss: 2.6044e-01, 5.0635e+01 Remaining Time: 02h 29min 20s LR: 1.00000e-04 \n",
      "2025-06-07 08:44:17,862 - INFO - Epoch 079: Avg. D/G Loss: 2.6287e-01, 5.0742e+01 Remaining Time: 02h 28min 37s LR: 1.00000e-04 \n",
      "2025-06-07 08:44:59,815 - INFO - Epoch 080: Avg. D/G Loss: 2.6589e-01, 5.0561e+01 Remaining Time: 02h 28min 01s LR: 1.00000e-04 \n",
      "2025-06-07 08:45:39,374 - INFO - Epoch 081: Avg. D/G Loss: 2.6202e-01, 5.0571e+01 Remaining Time: 02h 27min 18s LR: 1.00000e-04 \n",
      "2025-06-07 08:46:22,900 - INFO - Epoch 082: Avg. D/G Loss: 2.6251e-01, 5.0544e+01 Remaining Time: 02h 26min 46s LR: 1.00000e-04 \n",
      "2025-06-07 08:47:04,695 - INFO - Epoch 083: Avg. D/G Loss: 2.6388e-01, 5.0446e+01 Remaining Time: 02h 26min 09s LR: 1.00000e-04 \n",
      "2025-06-07 08:47:43,628 - INFO - Epoch 084: Avg. D/G Loss: 2.6615e-01, 5.0556e+01 Remaining Time: 02h 25min 25s LR: 1.00000e-04 \n",
      "2025-06-07 08:48:26,159 - INFO - Epoch 085: Avg. D/G Loss: 2.6357e-01, 5.0444e+01 Remaining Time: 02h 24min 50s LR: 1.00000e-04 \n",
      "2025-06-07 08:49:06,845 - INFO - Epoch 086: Avg. D/G Loss: 2.6296e-01, 5.0475e+01 Remaining Time: 02h 24min 10s LR: 1.00000e-04 \n",
      "2025-06-07 08:49:47,349 - INFO - Epoch 087: Avg. D/G Loss: 2.6112e-01, 5.0319e+01 Remaining Time: 02h 23min 30s LR: 1.00000e-04 \n",
      "2025-06-07 08:50:26,828 - INFO - Epoch 088: Avg. D/G Loss: 2.6393e-01, 5.0401e+01 Remaining Time: 02h 22min 47s LR: 1.00000e-04 \n",
      "2025-06-07 08:51:11,053 - INFO - Epoch 089: Avg. D/G Loss: 2.6330e-01, 5.0339e+01 Remaining Time: 02h 22min 16s LR: 1.00000e-04 \n",
      "2025-06-07 08:51:50,033 - INFO - Epoch 090: Avg. D/G Loss: 2.5771e-01, 5.0262e+01 Remaining Time: 02h 21min 32s LR: 1.00000e-04 \n",
      "2025-06-07 08:52:31,935 - INFO - Epoch 091: Avg. D/G Loss: 2.6388e-01, 5.0302e+01 Remaining Time: 02h 20min 55s LR: 1.00000e-04 \n",
      "2025-06-07 08:53:11,363 - INFO - Epoch 092: Avg. D/G Loss: 2.6240e-01, 5.0277e+01 Remaining Time: 02h 20min 12s LR: 1.00000e-04 \n",
      "2025-06-07 08:53:51,227 - INFO - Epoch 093: Avg. D/G Loss: 2.5944e-01, 5.0302e+01 Remaining Time: 02h 19min 30s LR: 1.00000e-04 \n",
      "2025-06-07 08:54:32,086 - INFO - Epoch 094: Avg. D/G Loss: 2.6056e-01, 5.0308e+01 Remaining Time: 02h 18min 51s LR: 1.00000e-04 \n",
      "2025-06-07 08:55:11,687 - INFO - Epoch 095: Avg. D/G Loss: 2.6242e-01, 5.0227e+01 Remaining Time: 02h 18min 08s LR: 1.00000e-04 \n",
      "2025-06-07 08:55:52,721 - INFO - Epoch 096: Avg. D/G Loss: 2.5764e-01, 5.0230e+01 Remaining Time: 02h 17min 29s LR: 1.00000e-04 \n",
      "2025-06-07 08:56:33,184 - INFO - Epoch 097: Avg. D/G Loss: 2.5781e-01, 5.0133e+01 Remaining Time: 02h 16min 49s LR: 1.00000e-04 \n",
      "2025-06-07 08:57:13,507 - INFO - Epoch 098: Avg. D/G Loss: 2.5974e-01, 5.0194e+01 Remaining Time: 02h 16min 08s LR: 1.00000e-04 \n",
      "2025-06-07 08:57:52,150 - INFO - Epoch 099: Avg. D/G Loss: 2.5830e-01, 5.0115e+01 Remaining Time: 02h 15min 24s LR: 1.00000e-04 \n",
      "2025-06-07 08:58:31,241 - INFO - Epoch 100: Avg. D/G Loss: 2.5923e-01, 5.0090e+01 Remaining Time: 02h 14min 41s LR: 1.00000e-04 \n",
      "2025-06-07 08:59:10,463 - INFO - Epoch 101: Avg. D/G Loss: 2.6066e-01, 5.0129e+01 Remaining Time: 02h 13min 58s LR: 1.00000e-04 \n",
      "2025-06-07 08:59:51,887 - INFO - Epoch 102: Avg. D/G Loss: 2.5947e-01, 5.0215e+01 Remaining Time: 02h 13min 20s LR: 1.00000e-04 \n",
      "2025-06-07 09:00:31,382 - INFO - Epoch 103: Avg. D/G Loss: 2.6049e-01, 5.0016e+01 Remaining Time: 02h 12min 37s LR: 1.00000e-04 \n",
      "2025-06-07 09:01:10,183 - INFO - Epoch 104: Avg. D/G Loss: 2.5372e-01, 4.9990e+01 Remaining Time: 02h 11min 54s LR: 1.00000e-04 \n",
      "2025-06-07 09:01:51,639 - INFO - Epoch 105: Avg. D/G Loss: 2.5816e-01, 4.9986e+01 Remaining Time: 02h 11min 16s LR: 1.00000e-04 \n",
      "2025-06-07 09:02:33,743 - INFO - Epoch 106: Avg. D/G Loss: 2.5296e-01, 4.9945e+01 Remaining Time: 02h 10min 38s LR: 1.00000e-04 \n",
      "2025-06-07 09:03:15,391 - INFO - Epoch 107: Avg. D/G Loss: 2.5721e-01, 5.0020e+01 Remaining Time: 02h 10min 00s LR: 1.00000e-04 \n",
      "2025-06-07 09:03:54,664 - INFO - Epoch 108: Avg. D/G Loss: 2.5156e-01, 4.9957e+01 Remaining Time: 02h 09min 18s LR: 1.00000e-04 \n",
      "2025-06-07 09:04:35,445 - INFO - Epoch 109: Avg. D/G Loss: 2.5516e-01, 5.0022e+01 Remaining Time: 02h 08min 38s LR: 1.00000e-04 \n",
      "2025-06-07 09:05:15,703 - INFO - Epoch 110: Avg. D/G Loss: 2.5215e-01, 4.9820e+01 Remaining Time: 02h 07min 57s LR: 1.00000e-04 \n",
      "2025-06-07 09:05:56,551 - INFO - Epoch 111: Avg. D/G Loss: 2.5438e-01, 5.0012e+01 Remaining Time: 02h 07min 17s LR: 1.00000e-04 \n",
      "2025-06-07 09:06:39,045 - INFO - Epoch 112: Avg. D/G Loss: 2.5156e-01, 4.9883e+01 Remaining Time: 02h 06min 40s LR: 1.00000e-04 \n",
      "2025-06-07 09:07:18,751 - INFO - Epoch 113: Avg. D/G Loss: 2.5385e-01, 4.9807e+01 Remaining Time: 02h 05min 59s LR: 1.00000e-04 \n",
      "2025-06-07 09:07:59,599 - INFO - Epoch 114: Avg. D/G Loss: 2.5106e-01, 4.9819e+01 Remaining Time: 02h 05min 19s LR: 1.00000e-04 \n",
      "2025-06-07 09:08:39,918 - INFO - Epoch 115: Avg. D/G Loss: 2.5048e-01, 4.9870e+01 Remaining Time: 02h 04min 38s LR: 1.00000e-04 \n",
      "2025-06-07 09:09:20,190 - INFO - Epoch 116: Avg. D/G Loss: 2.5561e-01, 4.9790e+01 Remaining Time: 02h 03min 58s LR: 1.00000e-04 \n",
      "2025-06-07 09:10:01,358 - INFO - Epoch 117: Avg. D/G Loss: 2.5330e-01, 4.9811e+01 Remaining Time: 02h 03min 18s LR: 1.00000e-04 \n",
      "2025-06-07 09:10:41,021 - INFO - Epoch 118: Avg. D/G Loss: 2.4687e-01, 4.9721e+01 Remaining Time: 02h 02min 37s LR: 1.00000e-04 \n",
      "2025-06-07 09:11:21,616 - INFO - Epoch 119: Avg. D/G Loss: 2.5026e-01, 4.9802e+01 Remaining Time: 02h 01min 57s LR: 1.00000e-04 \n",
      "2025-06-07 09:12:03,132 - INFO - Epoch 120: Avg. D/G Loss: 2.4951e-01, 4.9718e+01 Remaining Time: 02h 01min 18s LR: 1.00000e-04 \n",
      "2025-06-07 09:12:42,469 - INFO - Epoch 121: Avg. D/G Loss: 2.4824e-01, 4.9685e+01 Remaining Time: 02h 00min 36s LR: 1.00000e-04 \n",
      "2025-06-07 09:13:23,355 - INFO - Epoch 122: Avg. D/G Loss: 2.4818e-01, 4.9638e+01 Remaining Time: 01h 59min 56s LR: 1.00000e-04 \n",
      "2025-06-07 09:14:03,056 - INFO - Epoch 123: Avg. D/G Loss: 2.4823e-01, 4.9689e+01 Remaining Time: 01h 59min 14s LR: 1.00000e-04 \n",
      "2025-06-07 09:14:45,740 - INFO - Epoch 124: Avg. D/G Loss: 2.4775e-01, 4.9599e+01 Remaining Time: 01h 58min 37s LR: 1.00000e-04 \n",
      "2025-06-07 09:15:26,171 - INFO - Epoch 125: Avg. D/G Loss: 2.4739e-01, 4.9695e+01 Remaining Time: 01h 57min 57s LR: 1.00000e-04 \n",
      "2025-06-07 09:16:05,877 - INFO - Epoch 126: Avg. D/G Loss: 2.4767e-01, 4.9668e+01 Remaining Time: 01h 57min 15s LR: 1.00000e-04 \n",
      "2025-06-07 09:16:47,971 - INFO - Epoch 127: Avg. D/G Loss: 2.4879e-01, 4.9710e+01 Remaining Time: 01h 56min 37s LR: 1.00000e-04 \n",
      "2025-06-07 09:17:27,839 - INFO - Epoch 128: Avg. D/G Loss: 2.4510e-01, 4.9571e+01 Remaining Time: 01h 55min 56s LR: 1.00000e-04 \n",
      "2025-06-07 09:18:07,262 - INFO - Epoch 129: Avg. D/G Loss: 2.4844e-01, 4.9578e+01 Remaining Time: 01h 55min 14s LR: 1.00000e-04 \n",
      "2025-06-07 09:18:47,855 - INFO - Epoch 130: Avg. D/G Loss: 2.4843e-01, 4.9585e+01 Remaining Time: 01h 54min 34s LR: 1.00000e-04 \n",
      "2025-06-07 09:19:27,923 - INFO - Epoch 131: Avg. D/G Loss: 2.4945e-01, 4.9514e+01 Remaining Time: 01h 53min 53s LR: 1.00000e-04 \n",
      "2025-06-07 09:20:09,932 - INFO - Epoch 132: Avg. D/G Loss: 2.4507e-01, 4.9542e+01 Remaining Time: 01h 53min 14s LR: 1.00000e-04 \n",
      "2025-06-07 09:20:52,438 - INFO - Epoch 133: Avg. D/G Loss: 2.4724e-01, 4.9543e+01 Remaining Time: 01h 52min 36s LR: 1.00000e-04 \n",
      "2025-06-07 09:21:31,082 - INFO - Epoch 134: Avg. D/G Loss: 2.4807e-01, 4.9513e+01 Remaining Time: 01h 51min 54s LR: 1.00000e-04 \n",
      "2025-06-07 09:22:13,066 - INFO - Epoch 135: Avg. D/G Loss: 2.4661e-01, 4.9578e+01 Remaining Time: 01h 51min 15s LR: 1.00000e-04 \n",
      "2025-06-07 09:22:51,753 - INFO - Epoch 136: Avg. D/G Loss: 2.4544e-01, 4.9481e+01 Remaining Time: 01h 50min 32s LR: 1.00000e-04 \n",
      "2025-06-07 09:23:31,822 - INFO - Epoch 137: Avg. D/G Loss: 2.4385e-01, 4.9366e+01 Remaining Time: 01h 49min 52s LR: 1.00000e-04 \n",
      "2025-06-07 09:24:13,132 - INFO - Epoch 138: Avg. D/G Loss: 2.4419e-01, 4.9474e+01 Remaining Time: 01h 49min 12s LR: 1.00000e-04 \n",
      "2025-06-07 09:24:55,242 - INFO - Epoch 139: Avg. D/G Loss: 2.5082e-01, 4.9549e+01 Remaining Time: 01h 48min 34s LR: 1.00000e-04 \n",
      "2025-06-07 09:25:37,434 - INFO - Epoch 140: Avg. D/G Loss: 2.4951e-01, 4.9419e+01 Remaining Time: 01h 47min 55s LR: 1.00000e-04 \n",
      "2025-06-07 09:26:19,396 - INFO - Epoch 141: Avg. D/G Loss: 2.4498e-01, 4.9452e+01 Remaining Time: 01h 47min 16s LR: 1.00000e-04 \n",
      "2025-06-07 09:27:02,077 - INFO - Epoch 142: Avg. D/G Loss: 2.4364e-01, 4.9264e+01 Remaining Time: 01h 46min 38s LR: 1.00000e-04 \n",
      "2025-06-07 09:27:44,596 - INFO - Epoch 143: Avg. D/G Loss: 2.4573e-01, 4.9416e+01 Remaining Time: 01h 46min 00s LR: 1.00000e-04 \n",
      "2025-06-07 09:28:24,457 - INFO - Epoch 144: Avg. D/G Loss: 2.4464e-01, 4.9249e+01 Remaining Time: 01h 45min 19s LR: 1.00000e-04 \n",
      "2025-06-07 09:29:07,243 - INFO - Epoch 145: Avg. D/G Loss: 2.4396e-01, 4.9200e+01 Remaining Time: 01h 44min 41s LR: 1.00000e-04 \n",
      "2025-06-07 09:29:46,707 - INFO - Epoch 146: Avg. D/G Loss: 2.4625e-01, 4.9395e+01 Remaining Time: 01h 43min 59s LR: 1.00000e-04 \n",
      "2025-06-07 09:30:25,415 - INFO - Epoch 147: Avg. D/G Loss: 2.4401e-01, 4.9196e+01 Remaining Time: 01h 43min 16s LR: 1.00000e-04 \n",
      "2025-06-07 09:31:04,721 - INFO - Epoch 148: Avg. D/G Loss: 2.4230e-01, 4.9201e+01 Remaining Time: 01h 42min 35s LR: 1.00000e-04 \n",
      "2025-06-07 09:31:45,918 - INFO - Epoch 149: Avg. D/G Loss: 2.4269e-01, 4.9103e+01 Remaining Time: 01h 41min 55s LR: 1.00000e-04 \n",
      "2025-06-07 09:32:25,475 - INFO - Epoch 150: Avg. D/G Loss: 2.4656e-01, 4.9152e+01 Remaining Time: 01h 41min 14s LR: 1.00000e-04 \n",
      "2025-06-07 09:33:08,230 - INFO - Epoch 151: Avg. D/G Loss: 2.4211e-01, 4.9137e+01 Remaining Time: 01h 40min 35s LR: 1.00000e-04 \n",
      "2025-06-07 09:33:48,629 - INFO - Epoch 152: Avg. D/G Loss: 2.4461e-01, 4.9137e+01 Remaining Time: 01h 39min 55s LR: 1.00000e-04 \n",
      "2025-06-07 09:34:28,530 - INFO - Epoch 153: Avg. D/G Loss: 2.4409e-01, 4.9006e+01 Remaining Time: 01h 39min 13s LR: 1.00000e-04 \n",
      "2025-06-07 09:35:08,598 - INFO - Epoch 154: Avg. D/G Loss: 2.4017e-01, 4.9110e+01 Remaining Time: 01h 38min 33s LR: 1.00000e-04 \n",
      "2025-06-07 09:35:48,483 - INFO - Epoch 155: Avg. D/G Loss: 2.4265e-01, 4.8994e+01 Remaining Time: 01h 37min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:36:27,378 - INFO - Epoch 156: Avg. D/G Loss: 2.4312e-01, 4.9040e+01 Remaining Time: 01h 37min 09s LR: 1.00000e-04 \n",
      "2025-06-07 09:37:10,321 - INFO - Epoch 157: Avg. D/G Loss: 2.4448e-01, 4.8984e+01 Remaining Time: 01h 36min 31s LR: 1.00000e-04 \n",
      "2025-06-07 09:37:51,300 - INFO - Epoch 158: Avg. D/G Loss: 2.4024e-01, 4.9150e+01 Remaining Time: 01h 35min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:38:31,759 - INFO - Epoch 159: Avg. D/G Loss: 2.4005e-01, 4.8982e+01 Remaining Time: 01h 35min 11s LR: 1.00000e-04 \n",
      "2025-06-07 09:39:13,590 - INFO - Epoch 160: Avg. D/G Loss: 2.3939e-01, 4.8861e+01 Remaining Time: 01h 34min 31s LR: 1.00000e-04 \n",
      "2025-06-07 09:39:53,985 - INFO - Epoch 161: Avg. D/G Loss: 2.4239e-01, 4.9038e+01 Remaining Time: 01h 33min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:40:36,002 - INFO - Epoch 162: Avg. D/G Loss: 2.3948e-01, 4.9103e+01 Remaining Time: 01h 33min 11s LR: 1.00000e-04 \n",
      "2025-06-07 09:41:18,492 - INFO - Epoch 163: Avg. D/G Loss: 2.3931e-01, 4.8991e+01 Remaining Time: 01h 32min 32s LR: 1.00000e-04 \n",
      "2025-06-07 09:41:59,278 - INFO - Epoch 164: Avg. D/G Loss: 2.3502e-01, 4.8975e+01 Remaining Time: 01h 31min 52s LR: 1.00000e-04 \n",
      "2025-06-07 09:42:39,805 - INFO - Epoch 165: Avg. D/G Loss: 2.3790e-01, 4.8963e+01 Remaining Time: 01h 31min 12s LR: 1.00000e-04 \n",
      "2025-06-07 09:43:18,412 - INFO - Epoch 166: Avg. D/G Loss: 2.3929e-01, 4.9108e+01 Remaining Time: 01h 30min 29s LR: 1.00000e-04 \n",
      "2025-06-07 09:43:59,281 - INFO - Epoch 167: Avg. D/G Loss: 2.3684e-01, 4.8886e+01 Remaining Time: 01h 29min 49s LR: 1.00000e-04 \n",
      "2025-06-07 09:44:41,542 - INFO - Epoch 168: Avg. D/G Loss: 2.3770e-01, 4.8832e+01 Remaining Time: 01h 29min 10s LR: 1.00000e-04 \n",
      "2025-06-07 09:45:24,988 - INFO - Epoch 169: Avg. D/G Loss: 2.4011e-01, 4.9022e+01 Remaining Time: 01h 28min 32s LR: 1.00000e-04 \n",
      "2025-06-07 09:46:04,813 - INFO - Epoch 170: Avg. D/G Loss: 2.3688e-01, 4.8843e+01 Remaining Time: 01h 27min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:46:52,787 - INFO - Epoch 171: Avg. D/G Loss: 2.3890e-01, 4.8856e+01 Remaining Time: 01h 27min 16s LR: 1.00000e-04 \n",
      "2025-06-07 09:47:38,462 - INFO - Epoch 172: Avg. D/G Loss: 2.3522e-01, 4.8827e+01 Remaining Time: 01h 26min 39s LR: 1.00000e-04 \n",
      "2025-06-07 09:48:17,657 - INFO - Epoch 173: Avg. D/G Loss: 2.4002e-01, 4.8784e+01 Remaining Time: 01h 25min 57s LR: 1.00000e-04 \n",
      "2025-06-07 09:48:56,875 - INFO - Epoch 174: Avg. D/G Loss: 2.3954e-01, 4.8860e+01 Remaining Time: 01h 25min 16s LR: 1.00000e-04 \n",
      "2025-06-07 09:49:35,703 - INFO - Epoch 175: Avg. D/G Loss: 2.3475e-01, 4.8719e+01 Remaining Time: 01h 24min 34s LR: 1.00000e-04 \n",
      "2025-06-07 09:50:15,356 - INFO - Epoch 176: Avg. D/G Loss: 2.3919e-01, 4.8721e+01 Remaining Time: 01h 23min 52s LR: 1.00000e-04 \n",
      "2025-06-07 09:50:53,889 - INFO - Epoch 177: Avg. D/G Loss: 2.3682e-01, 4.8943e+01 Remaining Time: 01h 23min 10s LR: 1.00000e-04 \n",
      "2025-06-07 09:51:37,200 - INFO - Epoch 178: Avg. D/G Loss: 2.3921e-01, 4.8668e+01 Remaining Time: 01h 22min 32s LR: 1.00000e-04 \n",
      "2025-06-07 09:52:19,923 - INFO - Epoch 179: Avg. D/G Loss: 2.3414e-01, 4.8646e+01 Remaining Time: 01h 21min 52s LR: 1.00000e-04 \n",
      "2025-06-07 09:53:01,672 - INFO - Epoch 180: Avg. D/G Loss: 2.3815e-01, 4.8642e+01 Remaining Time: 01h 21min 13s LR: 1.00000e-04 \n",
      "2025-06-07 09:53:41,695 - INFO - Epoch 181: Avg. D/G Loss: 2.3511e-01, 4.8645e+01 Remaining Time: 01h 20min 32s LR: 1.00000e-04 \n",
      "2025-06-07 09:54:23,019 - INFO - Epoch 182: Avg. D/G Loss: 2.3785e-01, 4.8595e+01 Remaining Time: 01h 19min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:55:04,151 - INFO - Epoch 183: Avg. D/G Loss: 2.3881e-01, 4.8645e+01 Remaining Time: 01h 19min 11s LR: 1.00000e-04 \n",
      "2025-06-07 09:55:44,863 - INFO - Epoch 184: Avg. D/G Loss: 2.3440e-01, 4.8584e+01 Remaining Time: 01h 18min 31s LR: 1.00000e-04 \n",
      "2025-06-07 09:56:27,558 - INFO - Epoch 185: Avg. D/G Loss: 2.3889e-01, 4.8594e+01 Remaining Time: 01h 17min 51s LR: 1.00000e-04 \n",
      "2025-06-07 09:57:08,233 - INFO - Epoch 186: Avg. D/G Loss: 2.3489e-01, 4.8552e+01 Remaining Time: 01h 17min 11s LR: 1.00000e-04 \n",
      "2025-06-07 09:57:47,914 - INFO - Epoch 187: Avg. D/G Loss: 2.3834e-01, 4.8515e+01 Remaining Time: 01h 16min 29s LR: 1.00000e-04 \n",
      "2025-06-07 09:58:26,876 - INFO - Epoch 188: Avg. D/G Loss: 2.3793e-01, 4.8495e+01 Remaining Time: 01h 15min 48s LR: 1.00000e-04 \n",
      "2025-06-07 09:59:07,858 - INFO - Epoch 189: Avg. D/G Loss: 2.3500e-01, 4.8534e+01 Remaining Time: 01h 15min 07s LR: 1.00000e-04 \n",
      "2025-06-07 09:59:46,532 - INFO - Epoch 190: Avg. D/G Loss: 2.3271e-01, 4.8523e+01 Remaining Time: 01h 14min 26s LR: 1.00000e-04 \n",
      "2025-06-07 10:00:27,480 - INFO - Epoch 191: Avg. D/G Loss: 2.3970e-01, 4.8504e+01 Remaining Time: 01h 13min 45s LR: 1.00000e-04 \n",
      "2025-06-07 10:01:06,114 - INFO - Epoch 192: Avg. D/G Loss: 2.3997e-01, 4.8441e+01 Remaining Time: 01h 13min 04s LR: 1.00000e-04 \n",
      "2025-06-07 10:01:46,857 - INFO - Epoch 193: Avg. D/G Loss: 2.3666e-01, 4.8504e+01 Remaining Time: 01h 12min 23s LR: 1.00000e-04 \n",
      "2025-06-07 10:02:29,962 - INFO - Epoch 194: Avg. D/G Loss: 2.3826e-01, 4.8377e+01 Remaining Time: 01h 11min 44s LR: 1.00000e-04 \n",
      "2025-06-07 10:03:11,888 - INFO - Epoch 195: Avg. D/G Loss: 2.4053e-01, 4.8423e+01 Remaining Time: 01h 11min 04s LR: 1.00000e-04 \n",
      "2025-06-07 10:03:53,356 - INFO - Epoch 196: Avg. D/G Loss: 2.3765e-01, 4.8361e+01 Remaining Time: 01h 10min 24s LR: 1.00000e-04 \n",
      "2025-06-07 10:04:34,609 - INFO - Epoch 197: Avg. D/G Loss: 2.3793e-01, 4.8417e+01 Remaining Time: 01h 09min 43s LR: 1.00000e-04 \n",
      "2025-06-07 10:05:16,384 - INFO - Epoch 198: Avg. D/G Loss: 2.3875e-01, 4.8330e+01 Remaining Time: 01h 09min 03s LR: 1.00000e-04 \n",
      "2025-06-07 10:05:59,287 - INFO - Epoch 199: Avg. D/G Loss: 2.3995e-01, 4.8507e+01 Remaining Time: 01h 08min 24s LR: 1.00000e-04 \n",
      "2025-06-07 10:06:38,720 - INFO - Epoch 200: Avg. D/G Loss: 2.3389e-01, 4.8312e+01 Remaining Time: 01h 07min 43s LR: 1.00000e-04 \n",
      "2025-06-07 10:07:17,544 - INFO - Epoch 201: Avg. D/G Loss: 2.3716e-01, 4.8378e+01 Remaining Time: 01h 07min 01s LR: 1.00000e-04 \n",
      "2025-06-07 10:08:04,464 - INFO - Epoch 202: Avg. D/G Loss: 2.3607e-01, 4.8345e+01 Remaining Time: 01h 06min 24s LR: 1.00000e-04 \n",
      "2025-06-07 10:08:45,841 - INFO - Epoch 203: Avg. D/G Loss: 2.3290e-01, 4.8334e+01 Remaining Time: 01h 05min 43s LR: 1.00000e-04 \n",
      "2025-06-07 10:09:25,951 - INFO - Epoch 204: Avg. D/G Loss: 2.3465e-01, 4.8279e+01 Remaining Time: 01h 05min 02s LR: 1.00000e-04 \n",
      "2025-06-07 10:10:05,294 - INFO - Epoch 205: Avg. D/G Loss: 2.3041e-01, 4.8389e+01 Remaining Time: 01h 04min 21s LR: 1.00000e-04 \n",
      "2025-06-07 10:10:46,589 - INFO - Epoch 206: Avg. D/G Loss: 2.3085e-01, 4.8438e+01 Remaining Time: 01h 03min 41s LR: 1.00000e-04 \n",
      "2025-06-07 10:11:29,149 - INFO - Epoch 207: Avg. D/G Loss: 2.3287e-01, 4.8321e+01 Remaining Time: 01h 03min 01s LR: 1.00000e-04 \n",
      "2025-06-07 10:12:09,491 - INFO - Epoch 208: Avg. D/G Loss: 2.3188e-01, 4.8306e+01 Remaining Time: 01h 02min 20s LR: 1.00000e-04 \n",
      "2025-06-07 10:12:49,726 - INFO - Epoch 209: Avg. D/G Loss: 2.3550e-01, 4.8157e+01 Remaining Time: 01h 01min 39s LR: 1.00000e-04 \n",
      "2025-06-07 10:13:29,510 - INFO - Epoch 210: Avg. D/G Loss: 2.3128e-01, 4.8238e+01 Remaining Time: 01h 00min 58s LR: 1.00000e-04 \n",
      "2025-06-07 10:14:09,788 - INFO - Epoch 211: Avg. D/G Loss: 2.3503e-01, 4.8418e+01 Remaining Time: 01h 00min 17s LR: 1.00000e-04 \n",
      "2025-06-07 10:14:50,288 - INFO - Epoch 212: Avg. D/G Loss: 2.3605e-01, 4.8183e+01 Remaining Time: 00h 59min 37s LR: 1.00000e-04 \n",
      "2025-06-07 10:15:30,806 - INFO - Epoch 213: Avg. D/G Loss: 2.3352e-01, 4.8096e+01 Remaining Time: 00h 58min 56s LR: 1.00000e-04 \n",
      "2025-06-07 10:16:14,070 - INFO - Epoch 214: Avg. D/G Loss: 2.2997e-01, 4.8179e+01 Remaining Time: 00h 58min 16s LR: 1.00000e-04 \n",
      "2025-06-07 10:16:52,678 - INFO - Epoch 215: Avg. D/G Loss: 2.3585e-01, 4.8106e+01 Remaining Time: 00h 57min 35s LR: 1.00000e-04 \n",
      "2025-06-07 10:17:32,471 - INFO - Epoch 216: Avg. D/G Loss: 2.3239e-01, 4.8089e+01 Remaining Time: 00h 56min 54s LR: 1.00000e-04 \n",
      "2025-06-07 10:18:11,672 - INFO - Epoch 217: Avg. D/G Loss: 2.3533e-01, 4.8079e+01 Remaining Time: 00h 56min 13s LR: 1.00000e-04 \n",
      "2025-06-07 10:18:51,433 - INFO - Epoch 218: Avg. D/G Loss: 2.3234e-01, 4.8092e+01 Remaining Time: 00h 55min 32s LR: 1.00000e-04 \n",
      "2025-06-07 10:19:36,558 - INFO - Epoch 219: Avg. D/G Loss: 2.3512e-01, 4.8098e+01 Remaining Time: 00h 54min 53s LR: 1.00000e-04 \n",
      "2025-06-07 10:20:17,935 - INFO - Epoch 220: Avg. D/G Loss: 2.3026e-01, 4.8077e+01 Remaining Time: 00h 54min 12s LR: 1.00000e-04 \n",
      "2025-06-07 10:20:58,564 - INFO - Epoch 221: Avg. D/G Loss: 2.3565e-01, 4.8060e+01 Remaining Time: 00h 53min 32s LR: 1.00000e-04 \n",
      "2025-06-07 10:21:38,423 - INFO - Epoch 222: Avg. D/G Loss: 2.2978e-01, 4.8152e+01 Remaining Time: 00h 52min 51s LR: 1.00000e-04 \n",
      "2025-06-07 10:22:22,451 - INFO - Epoch 223: Avg. D/G Loss: 2.2948e-01, 4.8107e+01 Remaining Time: 00h 52min 11s LR: 1.00000e-04 \n",
      "2025-06-07 10:23:03,029 - INFO - Epoch 224: Avg. D/G Loss: 2.3287e-01, 4.8016e+01 Remaining Time: 00h 51min 30s LR: 1.00000e-04 \n",
      "2025-06-07 10:23:45,181 - INFO - Epoch 225: Avg. D/G Loss: 2.3035e-01, 4.7957e+01 Remaining Time: 00h 50min 50s LR: 1.00000e-04 \n",
      "2025-06-07 10:24:26,818 - INFO - Epoch 226: Avg. D/G Loss: 2.3292e-01, 4.8013e+01 Remaining Time: 00h 50min 10s LR: 1.00000e-04 \n",
      "2025-06-07 10:25:08,841 - INFO - Epoch 227: Avg. D/G Loss: 2.2943e-01, 4.7943e+01 Remaining Time: 00h 49min 30s LR: 1.00000e-04 \n",
      "2025-06-07 10:25:48,378 - INFO - Epoch 228: Avg. D/G Loss: 2.3293e-01, 4.8039e+01 Remaining Time: 00h 48min 49s LR: 1.00000e-04 \n",
      "2025-06-07 10:26:29,807 - INFO - Epoch 229: Avg. D/G Loss: 2.2764e-01, 4.7934e+01 Remaining Time: 00h 48min 08s LR: 1.00000e-04 \n",
      "2025-06-07 10:27:09,855 - INFO - Epoch 230: Avg. D/G Loss: 2.3210e-01, 4.7989e+01 Remaining Time: 00h 47min 27s LR: 1.00000e-04 \n",
      "2025-06-07 10:27:48,496 - INFO - Epoch 231: Avg. D/G Loss: 2.3028e-01, 4.7928e+01 Remaining Time: 00h 46min 46s LR: 1.00000e-04 \n",
      "2025-06-07 10:28:29,675 - INFO - Epoch 232: Avg. D/G Loss: 2.3176e-01, 4.7872e+01 Remaining Time: 00h 46min 05s LR: 1.00000e-04 \n",
      "2025-06-07 10:29:13,909 - INFO - Epoch 233: Avg. D/G Loss: 2.3235e-01, 4.7921e+01 Remaining Time: 00h 45min 26s LR: 1.00000e-04 \n",
      "2025-06-07 10:29:53,963 - INFO - Epoch 234: Avg. D/G Loss: 2.3041e-01, 4.7927e+01 Remaining Time: 00h 44min 45s LR: 1.00000e-04 \n",
      "2025-06-07 10:30:33,666 - INFO - Epoch 235: Avg. D/G Loss: 2.3119e-01, 4.7859e+01 Remaining Time: 00h 44min 04s LR: 1.00000e-04 \n",
      "2025-06-07 10:31:12,810 - INFO - Epoch 236: Avg. D/G Loss: 2.3048e-01, 4.8042e+01 Remaining Time: 00h 43min 23s LR: 1.00000e-04 \n",
      "2025-06-07 10:31:55,732 - INFO - Epoch 237: Avg. D/G Loss: 2.2775e-01, 4.7803e+01 Remaining Time: 00h 42min 43s LR: 1.00000e-04 \n",
      "2025-06-07 10:32:36,566 - INFO - Epoch 238: Avg. D/G Loss: 2.2827e-01, 4.7898e+01 Remaining Time: 00h 42min 02s LR: 1.00000e-04 \n",
      "2025-06-07 10:33:16,797 - INFO - Epoch 239: Avg. D/G Loss: 2.2670e-01, 4.7755e+01 Remaining Time: 00h 41min 21s LR: 1.00000e-04 \n",
      "2025-06-07 10:33:58,571 - INFO - Epoch 240: Avg. D/G Loss: 2.2971e-01, 4.7834e+01 Remaining Time: 00h 40min 41s LR: 1.00000e-04 \n",
      "2025-06-07 10:34:40,690 - INFO - Epoch 241: Avg. D/G Loss: 2.2657e-01, 4.7995e+01 Remaining Time: 00h 40min 01s LR: 1.00000e-04 \n",
      "2025-06-07 10:35:19,802 - INFO - Epoch 242: Avg. D/G Loss: 2.2711e-01, 4.7751e+01 Remaining Time: 00h 39min 19s LR: 1.00000e-04 \n",
      "2025-06-07 10:35:59,860 - INFO - Epoch 243: Avg. D/G Loss: 2.2827e-01, 4.7880e+01 Remaining Time: 00h 38min 39s LR: 1.00000e-04 \n",
      "2025-06-07 10:36:39,563 - INFO - Epoch 244: Avg. D/G Loss: 2.2969e-01, 4.7943e+01 Remaining Time: 00h 37min 58s LR: 1.00000e-04 \n",
      "2025-06-07 10:37:20,412 - INFO - Epoch 245: Avg. D/G Loss: 2.2496e-01, 4.7705e+01 Remaining Time: 00h 37min 17s LR: 1.00000e-04 \n",
      "2025-06-07 10:38:02,397 - INFO - Epoch 246: Avg. D/G Loss: 2.3277e-01, 4.7844e+01 Remaining Time: 00h 36min 37s LR: 1.00000e-04 \n",
      "2025-06-07 10:38:41,201 - INFO - Epoch 247: Avg. D/G Loss: 2.2930e-01, 4.7593e+01 Remaining Time: 00h 35min 56s LR: 1.00000e-04 \n",
      "2025-06-07 10:39:21,763 - INFO - Epoch 248: Avg. D/G Loss: 2.3051e-01, 4.7711e+01 Remaining Time: 00h 35min 15s LR: 1.00000e-04 \n",
      "2025-06-07 10:40:05,453 - INFO - Epoch 249: Avg. D/G Loss: 2.2925e-01, 4.7798e+01 Remaining Time: 00h 34min 35s LR: 1.00000e-04 \n",
      "2025-06-07 10:40:48,516 - INFO - Epoch 250: Avg. D/G Loss: 2.2939e-01, 4.7742e+01 Remaining Time: 00h 33min 55s LR: 1.00000e-04 \n",
      "2025-06-07 10:41:29,363 - INFO - Epoch 251: Avg. D/G Loss: 2.2689e-01, 4.7653e+01 Remaining Time: 00h 33min 14s LR: 1.00000e-04 \n",
      "2025-06-07 10:42:11,405 - INFO - Epoch 252: Avg. D/G Loss: 2.2839e-01, 4.7682e+01 Remaining Time: 00h 32min 33s LR: 1.00000e-04 \n",
      "2025-06-07 10:42:54,409 - INFO - Epoch 253: Avg. D/G Loss: 2.2571e-01, 4.7633e+01 Remaining Time: 00h 31min 53s LR: 1.00000e-04 \n",
      "2025-06-07 10:43:33,095 - INFO - Epoch 254: Avg. D/G Loss: 2.2468e-01, 4.7707e+01 Remaining Time: 00h 31min 12s LR: 1.00000e-04 \n",
      "2025-06-07 10:44:15,720 - INFO - Epoch 255: Avg. D/G Loss: 2.2557e-01, 4.7673e+01 Remaining Time: 00h 30min 32s LR: 1.00000e-04 \n",
      "2025-06-07 10:44:56,425 - INFO - Epoch 256: Avg. D/G Loss: 2.2670e-01, 4.7586e+01 Remaining Time: 00h 29min 51s LR: 1.00000e-04 \n",
      "2025-06-07 10:45:36,112 - INFO - Epoch 257: Avg. D/G Loss: 2.2557e-01, 4.7817e+01 Remaining Time: 00h 29min 10s LR: 1.00000e-04 \n",
      "2025-06-07 10:46:20,728 - INFO - Epoch 258: Avg. D/G Loss: 2.2271e-01, 4.7545e+01 Remaining Time: 00h 28min 30s LR: 1.00000e-04 \n",
      "2025-06-07 10:47:00,166 - INFO - Epoch 259: Avg. D/G Loss: 2.2629e-01, 4.7717e+01 Remaining Time: 00h 27min 49s LR: 1.00000e-04 \n",
      "2025-06-07 10:47:40,128 - INFO - Epoch 260: Avg. D/G Loss: 2.2645e-01, 4.7540e+01 Remaining Time: 00h 27min 08s LR: 1.00000e-04 \n",
      "2025-06-07 10:48:21,936 - INFO - Epoch 261: Avg. D/G Loss: 2.2995e-01, 4.7648e+01 Remaining Time: 00h 26min 28s LR: 1.00000e-04 \n",
      "2025-06-07 10:49:00,594 - INFO - Epoch 262: Avg. D/G Loss: 2.2960e-01, 4.7474e+01 Remaining Time: 00h 25min 47s LR: 1.00000e-04 \n",
      "2025-06-07 10:49:39,215 - INFO - Epoch 263: Avg. D/G Loss: 2.2639e-01, 4.7674e+01 Remaining Time: 00h 25min 06s LR: 1.00000e-04 \n",
      "2025-06-07 10:50:21,984 - INFO - Epoch 264: Avg. D/G Loss: 2.2517e-01, 4.7650e+01 Remaining Time: 00h 24min 25s LR: 1.00000e-04 \n",
      "2025-06-07 10:51:03,742 - INFO - Epoch 265: Avg. D/G Loss: 2.2615e-01, 4.7512e+01 Remaining Time: 00h 23min 45s LR: 1.00000e-04 \n",
      "2025-06-07 10:51:46,538 - INFO - Epoch 266: Avg. D/G Loss: 2.2192e-01, 4.7494e+01 Remaining Time: 00h 23min 04s LR: 1.00000e-04 \n",
      "2025-06-07 10:52:26,279 - INFO - Epoch 267: Avg. D/G Loss: 2.2446e-01, 4.7595e+01 Remaining Time: 00h 22min 23s LR: 1.00000e-04 \n",
      "2025-06-07 10:53:06,186 - INFO - Epoch 268: Avg. D/G Loss: 2.2649e-01, 4.7523e+01 Remaining Time: 00h 21min 42s LR: 1.00000e-04 \n",
      "2025-06-07 10:53:46,823 - INFO - Epoch 269: Avg. D/G Loss: 2.2345e-01, 4.7561e+01 Remaining Time: 00h 21min 02s LR: 1.00000e-04 \n",
      "2025-06-07 10:54:30,223 - INFO - Epoch 270: Avg. D/G Loss: 2.2266e-01, 4.7565e+01 Remaining Time: 00h 20min 21s LR: 1.00000e-04 \n",
      "2025-06-07 10:55:11,894 - INFO - Epoch 271: Avg. D/G Loss: 2.2394e-01, 4.7467e+01 Remaining Time: 00h 19min 41s LR: 1.00000e-04 \n",
      "2025-06-07 10:55:52,771 - INFO - Epoch 272: Avg. D/G Loss: 2.2191e-01, 4.7580e+01 Remaining Time: 00h 19min 00s LR: 1.00000e-04 \n",
      "2025-06-07 10:56:34,283 - INFO - Epoch 273: Avg. D/G Loss: 2.2011e-01, 4.7399e+01 Remaining Time: 00h 18min 19s LR: 1.00000e-04 \n",
      "2025-06-07 10:57:15,802 - INFO - Epoch 274: Avg. D/G Loss: 2.2278e-01, 4.7394e+01 Remaining Time: 00h 17min 39s LR: 1.00000e-04 \n",
      "2025-06-07 10:57:54,644 - INFO - Epoch 275: Avg. D/G Loss: 2.2341e-01, 4.7458e+01 Remaining Time: 00h 16min 58s LR: 1.00000e-04 \n",
      "2025-06-07 10:58:33,392 - INFO - Epoch 276: Avg. D/G Loss: 2.2246e-01, 4.7466e+01 Remaining Time: 00h 16min 17s LR: 1.00000e-04 \n",
      "2025-06-07 10:59:12,639 - INFO - Epoch 277: Avg. D/G Loss: 2.2220e-01, 4.7360e+01 Remaining Time: 00h 15min 36s LR: 1.00000e-04 \n",
      "2025-06-07 10:59:53,073 - INFO - Epoch 278: Avg. D/G Loss: 2.2210e-01, 4.7783e+01 Remaining Time: 00h 14min 55s LR: 1.00000e-04 \n",
      "2025-06-07 11:00:31,677 - INFO - Epoch 279: Avg. D/G Loss: 2.2258e-01, 4.7389e+01 Remaining Time: 00h 14min 14s LR: 1.00000e-04 \n",
      "2025-06-07 11:01:11,751 - INFO - Epoch 280: Avg. D/G Loss: 2.2239e-01, 4.7318e+01 Remaining Time: 00h 13min 34s LR: 1.00000e-04 \n",
      "2025-06-07 11:01:55,313 - INFO - Epoch 281: Avg. D/G Loss: 2.2253e-01, 4.7336e+01 Remaining Time: 00h 12min 53s LR: 1.00000e-04 \n",
      "2025-06-07 11:02:35,404 - INFO - Epoch 282: Avg. D/G Loss: 2.2177e-01, 4.7370e+01 Remaining Time: 00h 12min 12s LR: 1.00000e-04 \n",
      "2025-06-07 11:03:17,755 - INFO - Epoch 283: Avg. D/G Loss: 2.2086e-01, 4.7269e+01 Remaining Time: 00h 11min 32s LR: 1.00000e-04 \n",
      "2025-06-07 11:03:57,935 - INFO - Epoch 284: Avg. D/G Loss: 2.1829e-01, 4.7322e+01 Remaining Time: 00h 10min 51s LR: 1.00000e-04 \n",
      "2025-06-07 11:04:36,731 - INFO - Epoch 285: Avg. D/G Loss: 2.2151e-01, 4.7243e+01 Remaining Time: 00h 10min 10s LR: 1.00000e-04 \n",
      "2025-06-07 11:05:20,422 - INFO - Epoch 286: Avg. D/G Loss: 2.2323e-01, 4.7270e+01 Remaining Time: 00h 09min 30s LR: 1.00000e-04 \n",
      "2025-06-07 11:06:00,645 - INFO - Epoch 287: Avg. D/G Loss: 2.2156e-01, 4.7251e+01 Remaining Time: 00h 08min 49s LR: 1.00000e-04 \n",
      "2025-06-07 11:06:41,020 - INFO - Epoch 288: Avg. D/G Loss: 2.1965e-01, 4.7437e+01 Remaining Time: 00h 08min 08s LR: 1.00000e-04 \n",
      "2025-06-07 11:07:20,841 - INFO - Epoch 289: Avg. D/G Loss: 2.2221e-01, 4.7303e+01 Remaining Time: 00h 07min 27s LR: 1.00000e-04 \n",
      "2025-06-07 11:08:02,063 - INFO - Epoch 290: Avg. D/G Loss: 2.2017e-01, 4.7280e+01 Remaining Time: 00h 06min 47s LR: 1.00000e-04 \n",
      "2025-06-07 11:08:44,387 - INFO - Epoch 291: Avg. D/G Loss: 2.1693e-01, 4.7220e+01 Remaining Time: 00h 06min 06s LR: 1.00000e-04 \n",
      "2025-06-07 11:09:24,169 - INFO - Epoch 292: Avg. D/G Loss: 2.1774e-01, 4.7143e+01 Remaining Time: 00h 05min 25s LR: 1.00000e-04 \n",
      "2025-06-07 11:10:05,102 - INFO - Epoch 293: Avg. D/G Loss: 2.2045e-01, 4.7240e+01 Remaining Time: 00h 04min 45s LR: 1.00000e-04 \n",
      "2025-06-07 11:10:45,125 - INFO - Epoch 294: Avg. D/G Loss: 2.1715e-01, 4.7133e+01 Remaining Time: 00h 04min 04s LR: 1.00000e-04 \n",
      "2025-06-07 11:11:23,927 - INFO - Epoch 295: Avg. D/G Loss: 2.1992e-01, 4.7102e+01 Remaining Time: 00h 03min 23s LR: 1.00000e-04 \n",
      "2025-06-07 11:12:06,293 - INFO - Epoch 296: Avg. D/G Loss: 2.1971e-01, 4.7176e+01 Remaining Time: 00h 02min 42s LR: 1.00000e-04 \n",
      "2025-06-07 11:12:46,388 - INFO - Epoch 297: Avg. D/G Loss: 2.1890e-01, 4.7083e+01 Remaining Time: 00h 02min 02s LR: 1.00000e-04 \n",
      "2025-06-07 11:13:25,011 - INFO - Epoch 298: Avg. D/G Loss: 2.1680e-01, 4.7134e+01 Remaining Time: 00h 01min 21s LR: 1.00000e-04 \n",
      "2025-06-07 11:14:05,283 - INFO - Epoch 299: Avg. D/G Loss: 2.1938e-01, 4.7133e+01 Remaining Time: 00h 00min 40s LR: 1.00000e-04 \n",
      "2025-06-07 11:14:46,350 - INFO - Epoch 300: Avg. D/G Loss: 2.1894e-01, 4.7129e+01 Remaining Time: 00h 00min 00s LR: 1.00000e-04 \n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Training started on {device}\")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "loss_d_list: list = []\n",
    "loss_g_list: list = []\n",
    "total_time: float = 0.0\n",
    "\n",
    "for e in range(0, epochs):\n",
    "    total_d_loss: float = 0\n",
    "    total_g_loss: float = 0\n",
    "    start_time: float = time.time()\n",
    "\n",
    "    for b_idx, (mel, audio) in enumerate(data_loader):\n",
    "            mel, audio = mel.to(device), audio.to(device).unsqueeze(1)\n",
    "            for _ in range(n_disc_updates):\n",
    "                with torch.autocast(device_type=device):\n",
    "                    fake_waveform = generator(mel).detach()\n",
    "                    real_preds, _ = discriminator(audio)\n",
    "                    fake_preds, _ = discriminator(fake_waveform)\n",
    "                \n",
    "                d_loss = 0\n",
    "                for real_pred, fake_pred in zip(real_preds, fake_preds):\n",
    "                    d_loss += adversarial_loss(real_pred, torch.full_like(real_pred, 1 - label_smooth_val))\n",
    "                    d_loss += adversarial_loss(fake_pred, torch.full_like(fake_pred, label_smooth_val))\n",
    "                \n",
    "                disc_optim.zero_grad()\n",
    "                scaler.scale(d_loss).backward()\n",
    "                scaler.step(disc_optim)\n",
    "                scaler.update()\n",
    "\n",
    "                total_d_loss += d_loss.item()\n",
    "                if np.isnan(d_loss.item()):\n",
    "                    logger.info(\"Breaking due to NaN Discriminator loss.\")\n",
    "                    break\n",
    "\n",
    "            for _ in range(n_gen_updates):\n",
    "                with torch.autocast(device_type=device):\n",
    "                    fake_waveform = generator(mel)\n",
    "                    fake_preds, fake_feats = discriminator(fake_waveform)\n",
    "                    _, real_feats = discriminator(audio)\n",
    "                \n",
    "                g_adv_loss = 0\n",
    "                for fake_pred in fake_preds:\n",
    "                    g_adv_loss += adversarial_loss(fake_pred, torch.ones_like(fake_pred))\n",
    "\n",
    "                fm_loss = 0\n",
    "                num_fmaps = 0\n",
    "                for real_fmaps, fake_fmaps in zip(real_feats, fake_feats):\n",
    "                    for real_fmap, fake_fmap in zip(real_fmaps, fake_fmaps):\n",
    "                        fm_loss += l1_loss(fake_fmap, real_fmap.detach())\n",
    "                        num_fmaps += 1\n",
    "                fm_loss = fm_loss / num_fmaps\n",
    "\n",
    "                recon_loss = l1_loss(fake_waveform, audio)\n",
    "                g_loss = g_adv_loss + fm_loss_weight * fm_loss + recon_loss_weight * recon_loss\n",
    "\n",
    "                gen_optim.zero_grad()\n",
    "                scaler.scale(g_loss).backward()\n",
    "                scaler.step(gen_optim)\n",
    "                scaler.update()\n",
    "\n",
    "                total_g_loss += g_loss.item()\n",
    "                if np.isnan(g_loss.item()):\n",
    "                    logger.info(\"Breaking due to NaN Generator loss.\")\n",
    "                    break\n",
    "\n",
    "            if logger.getEffectiveLevel() == LIGHT_DEBUG:\n",
    "                current_batch = b_idx + 1\n",
    "                print(f\"\\r{time.strftime('%Y-%m-%d %H:%M:%S')},000 - LIGHT_DEBUG - Batch {current_batch:03d}/{len(data_loader):03d} D/G Loss: {d_loss.item():.3f} {g_loss.item():.3f}\", end='', flush=True)\n",
    "    else:\n",
    "        if logger.getEffectiveLevel() == LIGHT_DEBUG:\n",
    "            print(flush=True)\n",
    "\n",
    "        avg_d_loss = total_d_loss / len(data_loader)\n",
    "        avg_g_loss = total_g_loss / len(data_loader)\n",
    "        loss_d_list.append(avg_d_loss)\n",
    "        loss_g_list.append(avg_g_loss)\n",
    "\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        total_time += epoch_time\n",
    "        remaining_time = int((total_time / (e + 1)) * (epochs - e - 1))\n",
    "\n",
    "        logger.info(f\"Epoch {e + 1:03d}: Avg. D/G Loss: {avg_d_loss:.4e}, {avg_g_loss:.4e} Remaining Time: {remaining_time // 3600:02d}h {(remaining_time % 3600) // 60:02d}min {round(remaining_time % 60):02d}s LR: {gen_optim.param_groups[0]['lr']:.5e} \")\n",
    "        \n",
    "        if checkpoint_freq > 0 and (e + 1) % checkpoint_freq == 0:\n",
    "            checkpoint_path: str = f\"{full_model_path[:-4]}_epoch_{e + 1:03d}.pth\"\n",
    "            torch.save({\"generator\": generator.state_dict(), \"discriminator\": discriminator.state_dict(), \"gen_optim\": gen_optim.state_dict(), \"disc_optim\": disc_optim.state_dict() , \"epoch\": e + 1}, checkpoint_path)\n",
    "            if e + 1 != checkpoint_freq:\n",
    "                last_path: str = f\"{full_model_path[:-4]}_epoch_{(e + 1) - checkpoint_freq:03d}.pth\"\n",
    "                del_if_exists(last_path)\n",
    "            logger.light_debug(f\"Checkpoint saved model to {checkpoint_path}\")\n",
    "        continue\n",
    "    break\n",
    "\n",
    "\n",
    "torch.save({\"generator\": generator.state_dict(), \"discriminator\": discriminator.state_dict(), \"gen_optim\": gen_optim.state_dict(), \"disc_optim\": disc_optim.state_dict() , \"epoch\": e + 1}, full_model_path)\n",
    "\n",
    "logger.light_debug(f\"Saved model to {full_model_path}\")\n",
    "\n",
    "if checkpoint_freq > 0:\n",
    "    checkpoint_path: str = f\"{full_model_path[:-4]}_epoch_{e + 1 - ((e + 1) % checkpoint_freq):03d}.pth\"\n",
    "    del_if_exists(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50424b99",
   "metadata": {},
   "source": [
    "### Convert to wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a8a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idx: int = 100\n",
    "with torch.no_grad():\n",
    "    generated_wave = generator(torch.tensor(mel_data[file_idx]).unsqueeze(0).to(device))\n",
    "save_audio_file(generated_wave.cpu().numpy()[0,0], \"test.wav\", 32000)\n",
    "save_audio_file(audio_data[file_idx], \"test_real.wav\", 32000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
