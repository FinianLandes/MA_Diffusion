{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Diffusion Model\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.U_Net import *\n",
    "from Libraries.Diffusion import *\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = True\n",
    "\n",
    "logging_level: int = logging.INFO\n",
    "model_name: str = \"diffusion_v7\"\n",
    "full_model_path: str = path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, model_name + \".pth\"), remote_kernel)\n",
    "checkpoint_freq: int = 10 #0 for no checkpoint saving\n",
    "training_data_name: str = \"training_full_low_res\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "restart_training: bool = True #If True and model already exists optimizer and lr_scheduler are reset\n",
    "learning_rate: float = 5e-4 #Starting lr/first lr for Threshold Scheduler\n",
    "epochs: int = 100\n",
    "n_training_samples: int = 4000\n",
    "\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:01:40,506 - INFO - Data loaded with shape: (2000, 224, 416)\n"
     ]
    }
   ],
   "source": [
    "file: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))[:n_training_samples, ...]\n",
    "data_loader = create_dataloader(Audio_Data(file), conf[\"model\"].batch_size)\n",
    "logger.info(f\"Data loaded with shape: {file.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:01:42,296 - INFO - Model diffusion_v7 loaded with 72857025 Parameters\n"
     ]
    }
   ],
   "source": [
    "u_net = Conv_U_NET(in_channels=1,\n",
    "                    time_embed_dim=conf[\"model\"].time_embed_dim, \n",
    "                    n_starting_filters=conf[\"model\"].n_starting_filters, \n",
    "                    n_downsamples=conf[\"model\"].n_downsamples, \n",
    "                    activation=nn.SiLU(), \n",
    "                    device=device\n",
    "                ).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(u_net.parameters(), lr=learning_rate)\n",
    "scheduler = Threshold_LR(optimizer, [1, 0.1, 0.09, 0.85, 0.08, 0.07], [learning_rate, 2e-4, 1e-4, 1e-5, 1e-6, 1e-7])\n",
    "start_epoch: int = 0\n",
    "\n",
    "if os.path.exists(full_model_path):\n",
    "    model = torch.load(full_model_path, map_location=device)\n",
    "    u_net.load_state_dict(model[\"model\"])\n",
    "    if not restart_training:\n",
    "        optimizer.load_state_dict(model[\"optim\"])\n",
    "        scheduler.load_state_dict(model[\"scheduler\"])\n",
    "        start_epoch = model.get(\"epoch\", 0)\n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(u_net)} Parameters\")\n",
    "else: \n",
    "    logger.info(f\"Model {model_name} created with {count_parameters(u_net)} Parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion(model=u_net, \n",
    "                        noise_steps=conf[\"model\"].diffusion_timesteps, \n",
    "                        noise_schedule=\"linear\", \n",
    "                        input_dim=[conf[\"model\"].batch_size, 1, file.shape[-2], file.shape[-1]],\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "#diffusion.visualize_diffusion_steps(x=torch.Tensor(file[:1]), noise_schedule=noise_schedule, device=device, n_spectograms=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:01:42,500 - INFO - Training started on cuda\n",
      "2025-03-17 18:03:01,340 - INFO - Epoch 011: Avg. Loss: 8.00835e-02 Remaining Time: 02h 10min 04s LR: 1.00000e-04\n",
      "2025-03-17 18:04:22,276 - INFO - Epoch 012: Avg. Loss: 7.88112e-02 Remaining Time: 02h 10min 28s LR: 5.00000e-05\n",
      "2025-03-17 18:05:40,788 - INFO - Epoch 013: Avg. Loss: 8.03173e-02 Remaining Time: 02h 08min 24s LR: 1.00000e-04\n",
      "2025-03-17 18:07:01,559 - INFO - Epoch 014: Avg. Loss: 7.57898e-02 Remaining Time: 02h 07min 37s LR: 5.00000e-05\n",
      "2025-03-17 18:08:21,792 - INFO - Epoch 015: Avg. Loss: 7.64216e-02 Remaining Time: 02h 06min 26s LR: 5.00000e-05\n",
      "2025-03-17 18:09:41,813 - INFO - Epoch 016: Avg. Loss: 8.04569e-02 Remaining Time: 02h 05min 09s LR: 1.00000e-04\n",
      "2025-03-17 18:11:02,520 - INFO - Epoch 017: Avg. Loss: 7.80051e-02 Remaining Time: 02h 04min 00s LR: 5.00000e-05\n",
      "2025-03-17 18:12:24,995 - INFO - Epoch 018: Avg. Loss: 8.14918e-02 Remaining Time: 02h 03min 08s LR: 1.00000e-04\n",
      "2025-03-17 18:13:45,324 - INFO - Epoch 019: Avg. Loss: 7.66594e-02 Remaining Time: 02h 01min 48s LR: 5.00000e-05\n",
      "2025-03-17 18:15:04,591 - INFO - Epoch 020: Avg. Loss: 8.21956e-02 Remaining Time: 02h 00min 18s LR: 1.00000e-04\n",
      "2025-03-17 18:16:24,750 - INFO - Epoch 021: Avg. Loss: 7.75226e-02 Remaining Time: 01h 58min 49s LR: 5.00000e-05\n",
      "2025-03-17 18:17:44,395 - INFO - Epoch 022: Avg. Loss: 7.89245e-02 Remaining Time: 01h 57min 26s LR: 5.00000e-05\n",
      "2025-03-17 18:19:04,492 - INFO - Epoch 023: Avg. Loss: 7.54908e-02 Remaining Time: 01h 56min 06s LR: 5.00000e-05\n",
      "2025-03-17 18:20:24,483 - INFO - Epoch 024: Avg. Loss: 7.71589e-02 Remaining Time: 01h 54min 45s LR: 5.00000e-05\n",
      "2025-03-17 18:21:45,419 - INFO - Epoch 025: Avg. Loss: 7.71568e-02 Remaining Time: 01h 53min 30s LR: 5.00000e-05\n",
      "2025-03-17 18:23:05,251 - INFO - Epoch 026: Avg. Loss: 7.85583e-02 Remaining Time: 01h 52min 08s LR: 5.00000e-05\n",
      "2025-03-17 18:24:25,729 - INFO - Epoch 027: Avg. Loss: 8.08866e-02 Remaining Time: 01h 50min 50s LR: 1.00000e-04\n",
      "2025-03-17 18:25:47,016 - INFO - Epoch 028: Avg. Loss: 8.05939e-02 Remaining Time: 01h 49min 35s LR: 1.00000e-04\n",
      "2025-03-17 18:27:06,718 - INFO - Epoch 029: Avg. Loss: 7.52784e-02 Remaining Time: 01h 48min 13s LR: 5.00000e-05\n",
      "2025-03-17 18:28:27,590 - INFO - Epoch 030: Avg. Loss: 7.63055e-02 Remaining Time: 01h 46min 56s LR: 5.00000e-05\n",
      "2025-03-17 18:29:51,388 - INFO - Epoch 031: Avg. Loss: 8.25183e-02 Remaining Time: 01h 45min 45s LR: 1.00000e-04\n",
      "2025-03-17 18:31:09,877 - INFO - Epoch 032: Avg. Loss: 7.57565e-02 Remaining Time: 01h 44min 18s LR: 5.00000e-05\n",
      "2025-03-17 18:32:32,360 - INFO - Epoch 033: Avg. Loss: 7.59552e-02 Remaining Time: 01h 43min 05s LR: 5.00000e-05\n",
      "2025-03-17 18:33:54,272 - INFO - Epoch 034: Avg. Loss: 7.91173e-02 Remaining Time: 01h 41min 50s LR: 5.00000e-05\n",
      "2025-03-17 18:35:14,599 - INFO - Epoch 035: Avg. Loss: 7.78030e-02 Remaining Time: 01h 40min 29s LR: 5.00000e-05\n",
      "2025-03-17 18:36:33,964 - INFO - Epoch 036: Avg. Loss: 7.30367e-02 Remaining Time: 01h 39min 06s LR: 5.00000e-05\n",
      "2025-03-17 18:37:53,074 - INFO - Epoch 037: Avg. Loss: 7.16432e-02 Remaining Time: 01h 37min 42s LR: 5.00000e-05\n",
      "2025-03-17 18:39:15,460 - INFO - Epoch 038: Avg. Loss: 7.83240e-02 Remaining Time: 01h 36min 27s LR: 5.00000e-05\n",
      "2025-03-17 18:40:34,013 - INFO - Epoch 039: Avg. Loss: 7.73799e-02 Remaining Time: 01h 35min 03s LR: 5.00000e-05\n",
      "2025-03-17 18:41:54,385 - INFO - Epoch 040: Avg. Loss: 7.33035e-02 Remaining Time: 01h 33min 42s LR: 5.00000e-05\n",
      "2025-03-17 18:43:17,574 - INFO - Epoch 041: Avg. Loss: 7.98193e-02 Remaining Time: 01h 32min 26s LR: 5.00000e-05\n",
      "2025-03-17 18:44:40,995 - INFO - Epoch 042: Avg. Loss: 7.69768e-02 Remaining Time: 01h 31min 12s LR: 5.00000e-05\n",
      "2025-03-17 18:46:00,604 - INFO - Epoch 043: Avg. Loss: 8.22946e-02 Remaining Time: 01h 29min 50s LR: 1.00000e-04\n",
      "2025-03-17 18:47:20,557 - INFO - Epoch 044: Avg. Loss: 7.53316e-02 Remaining Time: 01h 28min 29s LR: 5.00000e-05\n",
      "2025-03-17 18:48:40,985 - INFO - Epoch 045: Avg. Loss: 7.21795e-02 Remaining Time: 01h 27min 08s LR: 5.00000e-05\n",
      "2025-03-17 18:50:00,850 - INFO - Epoch 046: Avg. Loss: 7.58395e-02 Remaining Time: 01h 25min 47s LR: 5.00000e-05\n",
      "2025-03-17 18:51:19,889 - INFO - Epoch 047: Avg. Loss: 8.10414e-02 Remaining Time: 01h 24min 24s LR: 1.00000e-04\n",
      "2025-03-17 18:52:39,329 - INFO - Epoch 048: Avg. Loss: 7.24281e-02 Remaining Time: 01h 23min 02s LR: 5.00000e-05\n",
      "2025-03-17 18:53:59,536 - INFO - Epoch 049: Avg. Loss: 7.77741e-02 Remaining Time: 01h 21min 41s LR: 5.00000e-05\n",
      "2025-03-17 18:55:18,992 - INFO - Epoch 050: Avg. Loss: 7.20347e-02 Remaining Time: 01h 20min 20s LR: 5.00000e-05\n",
      "2025-03-17 18:56:41,004 - INFO - Epoch 051: Avg. Loss: 7.12492e-02 Remaining Time: 01h 19min 00s LR: 5.00000e-05\n",
      "2025-03-17 18:58:00,037 - INFO - Epoch 052: Avg. Loss: 7.80510e-02 Remaining Time: 01h 17min 38s LR: 5.00000e-05\n",
      "2025-03-17 18:59:21,642 - INFO - Epoch 053: Avg. Loss: 7.65881e-02 Remaining Time: 01h 16min 20s LR: 5.00000e-05\n",
      "2025-03-17 19:00:40,175 - INFO - Epoch 054: Avg. Loss: 7.17656e-02 Remaining Time: 01h 14min 57s LR: 5.00000e-05\n",
      "2025-03-17 19:01:59,585 - INFO - Epoch 055: Avg. Loss: 7.44911e-02 Remaining Time: 01h 13min 36s LR: 5.00000e-05\n",
      "2025-03-17 19:03:18,439 - INFO - Epoch 056: Avg. Loss: 7.21542e-02 Remaining Time: 01h 12min 14s LR: 5.00000e-05\n",
      "2025-03-17 19:04:38,348 - INFO - Epoch 057: Avg. Loss: 7.22315e-02 Remaining Time: 01h 10min 53s LR: 5.00000e-05\n",
      "2025-03-17 19:05:58,550 - INFO - Epoch 058: Avg. Loss: 7.61067e-02 Remaining Time: 01h 09min 33s LR: 5.00000e-05\n",
      "2025-03-17 19:07:17,640 - INFO - Epoch 059: Avg. Loss: 7.63056e-02 Remaining Time: 01h 08min 11s LR: 5.00000e-05\n",
      "2025-03-17 19:08:36,912 - INFO - Epoch 060: Avg. Loss: 7.38031e-02 Remaining Time: 01h 06min 50s LR: 5.00000e-05\n",
      "2025-03-17 19:09:56,636 - INFO - Epoch 061: Avg. Loss: 7.40193e-02 Remaining Time: 01h 05min 28s LR: 5.00000e-05\n",
      "2025-03-17 19:11:15,545 - INFO - Epoch 062: Avg. Loss: 7.42807e-02 Remaining Time: 01h 04min 07s LR: 5.00000e-05\n",
      "2025-03-17 19:12:35,937 - INFO - Epoch 063: Avg. Loss: 7.53188e-02 Remaining Time: 01h 02min 47s LR: 5.00000e-05\n",
      "2025-03-17 19:13:55,867 - INFO - Epoch 064: Avg. Loss: 6.80674e-02 Remaining Time: 01h 01min 27s LR: 5.00000e-05\n",
      "2025-03-17 19:15:17,378 - INFO - Epoch 065: Avg. Loss: 6.99034e-02 Remaining Time: 01h 00min 08s LR: 5.00000e-05\n",
      "2025-03-17 19:16:35,940 - INFO - Epoch 066: Avg. Loss: 7.36007e-02 Remaining Time: 00h 58min 46s LR: 5.00000e-05\n",
      "2025-03-17 19:17:54,472 - INFO - Epoch 067: Avg. Loss: 7.11018e-02 Remaining Time: 00h 57min 25s LR: 5.00000e-05\n",
      "2025-03-17 19:19:13,624 - INFO - Epoch 068: Avg. Loss: 7.20516e-02 Remaining Time: 00h 56min 04s LR: 5.00000e-05\n",
      "2025-03-17 19:20:33,173 - INFO - Epoch 069: Avg. Loss: 6.83939e-02 Remaining Time: 00h 54min 43s LR: 5.00000e-05\n",
      "2025-03-17 19:21:53,512 - INFO - Epoch 070: Avg. Loss: 7.22531e-02 Remaining Time: 00h 53min 24s LR: 5.00000e-05\n",
      "2025-03-17 19:23:15,343 - INFO - Epoch 071: Avg. Loss: 7.34228e-02 Remaining Time: 00h 52min 04s LR: 5.00000e-05\n",
      "2025-03-17 19:24:35,597 - INFO - Epoch 072: Avg. Loss: 7.77697e-02 Remaining Time: 00h 50min 44s LR: 5.00000e-05\n",
      "2025-03-17 19:25:55,778 - INFO - Epoch 073: Avg. Loss: 7.57001e-02 Remaining Time: 00h 49min 24s LR: 5.00000e-05\n",
      "2025-03-17 19:27:14,655 - INFO - Epoch 074: Avg. Loss: 6.42728e-02 Remaining Time: 00h 48min 03s LR: 5.00000e-05\n",
      "2025-03-17 19:28:34,641 - INFO - Epoch 075: Avg. Loss: 6.72948e-02 Remaining Time: 00h 46min 43s LR: 5.00000e-05\n",
      "2025-03-17 19:29:53,793 - INFO - Epoch 076: Avg. Loss: 7.49712e-02 Remaining Time: 00h 45min 22s LR: 5.00000e-05\n",
      "2025-03-17 19:31:14,149 - INFO - Epoch 077: Avg. Loss: 7.03549e-02 Remaining Time: 00h 44min 02s LR: 5.00000e-05\n",
      "2025-03-17 19:32:37,943 - INFO - Epoch 078: Avg. Loss: 7.71990e-02 Remaining Time: 00h 42min 44s LR: 5.00000e-05\n",
      "2025-03-17 19:33:58,300 - INFO - Epoch 079: Avg. Loss: 6.72675e-02 Remaining Time: 00h 41min 24s LR: 5.00000e-05\n",
      "2025-03-17 19:35:17,361 - INFO - Epoch 080: Avg. Loss: 6.87618e-02 Remaining Time: 00h 40min 03s LR: 5.00000e-05\n",
      "2025-03-17 19:36:37,928 - INFO - Epoch 081: Avg. Loss: 6.80380e-02 Remaining Time: 00h 38min 43s LR: 5.00000e-05\n",
      "2025-03-17 19:37:57,658 - INFO - Epoch 082: Avg. Loss: 6.54193e-02 Remaining Time: 00h 37min 23s LR: 5.00000e-05\n",
      "2025-03-17 19:39:17,463 - INFO - Epoch 083: Avg. Loss: 7.28472e-02 Remaining Time: 00h 36min 02s LR: 5.00000e-05\n",
      "2025-03-17 19:40:37,718 - INFO - Epoch 084: Avg. Loss: 6.80591e-02 Remaining Time: 00h 34min 42s LR: 5.00000e-05\n",
      "2025-03-17 19:41:58,281 - INFO - Epoch 085: Avg. Loss: 7.48261e-02 Remaining Time: 00h 33min 22s LR: 5.00000e-05\n",
      "2025-03-17 19:43:22,818 - INFO - Epoch 086: Avg. Loss: 7.40669e-02 Remaining Time: 00h 32min 04s LR: 5.00000e-05\n",
      "2025-03-17 19:44:43,505 - INFO - Epoch 087: Avg. Loss: 7.47646e-02 Remaining Time: 00h 30min 44s LR: 5.00000e-05\n",
      "2025-03-17 19:46:05,462 - INFO - Epoch 088: Avg. Loss: 7.23042e-02 Remaining Time: 00h 29min 24s LR: 5.00000e-05\n",
      "2025-03-17 19:47:25,129 - INFO - Epoch 089: Avg. Loss: 7.33159e-02 Remaining Time: 00h 28min 04s LR: 5.00000e-05\n",
      "2025-03-17 19:48:43,934 - INFO - Epoch 090: Avg. Loss: 7.32190e-02 Remaining Time: 00h 26min 43s LR: 5.00000e-05\n",
      "2025-03-17 19:50:05,853 - INFO - Epoch 091: Avg. Loss: 7.38876e-02 Remaining Time: 00h 25min 23s LR: 5.00000e-05\n",
      "2025-03-17 19:51:24,460 - INFO - Epoch 092: Avg. Loss: 6.80631e-02 Remaining Time: 00h 24min 03s LR: 5.00000e-05\n",
      "2025-03-17 19:52:44,795 - INFO - Epoch 093: Avg. Loss: 7.45232e-02 Remaining Time: 00h 22min 42s LR: 5.00000e-05\n",
      "2025-03-17 19:54:03,688 - INFO - Epoch 094: Avg. Loss: 6.39234e-02 Remaining Time: 00h 21min 22s LR: 5.00000e-05\n"
     ]
    }
   ],
   "source": [
    "x = diffusion.train(epochs=epochs, \n",
    "                    data_loader=data_loader, \n",
    "                    loss_function=nn.MSELoss(),\n",
    "                    optimizer=optimizer, \n",
    "                    lr_scheduler=scheduler, \n",
    "                    gradient_accum=conf[\"model\"].gradient_accum,\n",
    "                    checkpoint_freq=checkpoint_freq, \n",
    "                    model_path=full_model_path, \n",
    "                    start_epoch=start_epoch\n",
    "                )\n",
    "scatter_plot(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
