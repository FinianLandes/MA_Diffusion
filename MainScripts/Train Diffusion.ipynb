{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Diffusion Model\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.3)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (23.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2020.6.20)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.61.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soxr, msgpack, llvmlite, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.0 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.U_Net import *\n",
    "from Libraries.Diffusion import *\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = True\n",
    "\n",
    "logging_level: int = logging.INFO\n",
    "model_name: str = \"diffusion_v6\"\n",
    "full_model_path: str = path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, model_name + \".pth\"), remote_kernel)\n",
    "checkpoint_freq: int = 10 #0 for no checkpoint saving\n",
    "training_data_name: str = \"training_full_low_res\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "restart_training: bool = True #If True and model already exists optimizer and lr_scheduler are reset\n",
    "learning_rate: float = 5e-4\n",
    "epochs: int = 100\n",
    "n_training_samples: int = 2000\n",
    "\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:00:14,017 - INFO - Data loaded with shape: (2000, 224, 416)\n"
     ]
    }
   ],
   "source": [
    "file: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))[:n_training_samples, ...]\n",
    "data_loader = create_dataloader(Audio_Data(file), conf[\"model\"].batch_size)\n",
    "logger.info(f\"Data loaded with shape: {file.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:00:16,052 - INFO - Model diffusion_v6 created with 69306945 Parameters\n"
     ]
    }
   ],
   "source": [
    "u_net = Conv_U_NET(in_channels=1,\n",
    "                    time_embed_dim=conf[\"model\"].time_embed_dim, \n",
    "                    n_starting_filters=conf[\"model\"].n_starting_filters, \n",
    "                    n_downsamples=conf[\"model\"].n_downsamples, \n",
    "                    activation=nn.SiLU(), \n",
    "                    device=device\n",
    "                ).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(u_net.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", factor=0.8, patience=5, threshold=0, threshold_mode=\"rel\", cooldown=0,min_lr=1e-6)\n",
    "start_epoch: int = 0\n",
    "\n",
    "if os.path.exists(full_model_path):\n",
    "    model = torch.load(full_model_path, map_location=device)\n",
    "    u_net.load_state_dict(model[\"model\"])\n",
    "    if not restart_training:\n",
    "        optimizer.load_state_dict(model[\"optim\"])\n",
    "        scheduler.load_state_dict(model[\"scheduler\"])\n",
    "        start_epoch = model.get(\"epoch\", 0)\n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(u_net)} Parameters\")\n",
    "else: \n",
    "    logger.info(f\"Model {model_name} created with {count_parameters(u_net)} Parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion(model=u_net, \n",
    "                        noise_steps=conf[\"model\"].diffusion_timesteps, \n",
    "                        noise_schedule=\"linear\", \n",
    "                        input_dim=[conf[\"model\"].batch_size, 1, file.shape[-2], file.shape[-1]],\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "#diffusion.visualize_diffusion_steps(x=torch.Tensor(file[:1]), noise_schedule=noise_schedule, device=device, n_spectograms=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:00:16,345 - INFO - Training started on cuda\n",
      "2025-03-16 15:03:22,151 - INFO - Epoch 001: Avg. Loss: 1.00999e+00 Remaining Time: 05h 06min 34s LR: 5.00000e-04\n",
      "2025-03-16 15:06:29,032 - INFO - Epoch 002: Avg. Loss: 9.57198e-01 Remaining Time: 05h 04min 21s LR: 5.00000e-04\n",
      "2025-03-16 15:09:36,556 - INFO - Epoch 003: Avg. Loss: 7.98481e-01 Remaining Time: 05h 01min 53s LR: 5.00000e-04\n",
      "2025-03-16 15:12:44,214 - INFO - Epoch 004: Avg. Loss: 6.87070e-01 Remaining Time: 04h 59min 08s LR: 5.00000e-04\n",
      "2025-03-16 15:15:54,119 - INFO - Epoch 005: Avg. Loss: 6.28756e-01 Remaining Time: 04h 56min 57s LR: 5.00000e-04\n",
      "2025-03-16 15:19:02,340 - INFO - Epoch 006: Avg. Loss: 5.68245e-01 Remaining Time: 04h 54min 00s LR: 5.00000e-04\n",
      "2025-03-16 15:22:12,331 - INFO - Epoch 007: Avg. Loss: 5.35603e-01 Remaining Time: 04h 51min 23s LR: 5.00000e-04\n",
      "2025-03-16 15:25:20,357 - INFO - Epoch 008: Avg. Loss: 4.87659e-01 Remaining Time: 04h 48min 16s LR: 5.00000e-04\n",
      "2025-03-16 15:28:28,649 - INFO - Epoch 009: Avg. Loss: 3.88083e-01 Remaining Time: 04h 45min 10s LR: 5.00000e-04\n",
      "2025-03-16 15:31:38,840 - INFO - Epoch 010: Avg. Loss: 2.94070e-01 Remaining Time: 04h 42min 22s LR: 5.00000e-04\n",
      "2025-03-16 15:34:49,579 - INFO - Epoch 011: Avg. Loss: 2.55618e-01 Remaining Time: 04h 39min 23s LR: 5.00000e-04\n",
      "2025-03-16 15:37:55,706 - INFO - Epoch 012: Avg. Loss: 2.23074e-01 Remaining Time: 04h 35min 58s LR: 5.00000e-04\n",
      "2025-03-16 15:41:01,393 - INFO - Epoch 013: Avg. Loss: 2.06149e-01 Remaining Time: 04h 32min 33s LR: 5.00000e-04\n",
      "2025-03-16 15:44:09,276 - INFO - Epoch 014: Avg. Loss: 1.87264e-01 Remaining Time: 04h 29min 25s LR: 5.00000e-04\n",
      "2025-03-16 15:47:18,364 - INFO - Epoch 015: Avg. Loss: 1.82781e-01 Remaining Time: 04h 26min 23s LR: 5.00000e-04\n",
      "2025-03-16 15:50:25,736 - INFO - Epoch 016: Avg. Loss: 1.69079e-01 Remaining Time: 04h 23min 12s LR: 5.00000e-04\n",
      "2025-03-16 15:53:33,156 - INFO - Epoch 017: Avg. Loss: 1.61444e-01 Remaining Time: 04h 20min 01s LR: 5.00000e-04\n",
      "2025-03-16 15:56:43,525 - INFO - Epoch 018: Avg. Loss: 1.53245e-01 Remaining Time: 04h 17min 04s LR: 5.00000e-04\n",
      "2025-03-16 15:59:50,607 - INFO - Epoch 019: Avg. Loss: 1.50091e-01 Remaining Time: 04h 13min 51s LR: 5.00000e-04\n",
      "2025-03-16 16:03:00,083 - INFO - Epoch 020: Avg. Loss: 1.38997e-01 Remaining Time: 04h 10min 49s LR: 5.00000e-04\n",
      "2025-03-16 16:06:11,952 - INFO - Epoch 021: Avg. Loss: 1.40228e-01 Remaining Time: 04h 07min 49s LR: 5.00000e-04\n",
      "2025-03-16 16:09:19,637 - INFO - Epoch 022: Avg. Loss: 1.39322e-01 Remaining Time: 04h 04min 39s LR: 5.00000e-04\n"
     ]
    }
   ],
   "source": [
    "x = diffusion.train(epochs=epochs, \n",
    "                    data_loader=data_loader, \n",
    "                    loss_function=nn.MSELoss(),\n",
    "                    optimizer=optimizer, \n",
    "                    lr_scheduler=scheduler, \n",
    "                    gradient_accum=conf[\"model\"].gradient_accum,\n",
    "                    checkpoint_freq=checkpoint_freq, \n",
    "                    model_path=full_model_path, \n",
    "                    start_epoch=start_epoch\n",
    "                )\n",
    "scatter_plot(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
