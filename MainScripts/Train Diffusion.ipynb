{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Diffusion Model\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.U_Net import *\n",
    "from Libraries.Diffusion import *\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = True\n",
    "\n",
    "logging_level: int = logging.INFO\n",
    "model_name: str = \"diffusion_cifar10\"\n",
    "full_model_path: str = path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, model_name + \".pth\"), remote_kernel)\n",
    "checkpoint_freq: int = 10 #0 for no checkpoint saving\n",
    "training_data_name: str = \"training_full_low_res\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "restart_training: bool = True #If True and model already exists optimizer and lr_scheduler are reset\n",
    "learning_rate: float = 5e-4 #Starting lr/first lr for Threshold Scheduler\n",
    "epochs: int = 200\n",
    "n_training_samples: int = 2000\n",
    "\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 20:00:14,141 - LIGHT_DEBUG - Ndarray loaded from ../Data/training_full_low_res.npy of shape: (7087, 224, 416)\n",
      "2025-04-28 20:00:15,027 - INFO - Data loaded with shape: (2000, 224, 416)\n"
     ]
    }
   ],
   "source": [
    "file: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))[:n_training_samples, ...]\n",
    "data_loader = create_dataloader(Audio_Data(file), conf[\"model\"].batch_size)\n",
    "logger.info(f\"Data loaded with shape: {file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "])\n",
    "\n",
    "cifar10_train = torchvision.datasets.CIFAR10(\n",
    "    root=path_to_remote_path(conf[\"paths\"].data_path, remote_kernel), \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "indices = np.random.choice(len(cifar10_train), size=5000, replace=False)\n",
    "cifar10_subset = Subset(cifar10_train, indices)\n",
    "data_loader = DataLoader(cifar10_train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "#### U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net = U_NET(in_channels=1,\n",
    "            channels=[16, 32],\n",
    "            res_blocks=[2, 4],\n",
    "            factors=[2, 2],\n",
    "            attentions=[0, 1], \n",
    "            attention_heads=8,\n",
    "            attention_features=48,\n",
    "            activation=nn.GELU(), \n",
    "            embeding_dim=conf[\"model\"].time_embed_dim, \n",
    "            device=device\n",
    "            ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 12:16:42,340 - INFO - Model diffusion2_v0 created with 50226237 Parameters\n"
     ]
    }
   ],
   "source": [
    "u_net = U_NET(in_channels=1,\n",
    "            channels=[64, 128, 256, 512],\n",
    "            res_blocks=[12, 2, 2, 2],\n",
    "            factors=[ 2, 2, 2, 2],\n",
    "            attentions=[ 0, 0, 0, 1], \n",
    "            attention_heads=8,\n",
    "            attention_features=48,\n",
    "            activation=nn.GELU(), \n",
    "            embeding_dim=conf[\"model\"].time_embed_dim, \n",
    "            device=device\n",
    "            ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Net loading if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 19:47:24,327 - INFO - Model diffusion_cifar10 created with 312229 Parameters\n"
     ]
    }
   ],
   "source": [
    "ema = EMA(u_net, decay = 0.99)\n",
    "optimizer = optim.Adam(u_net.parameters(), lr=learning_rate)\n",
    "#scheduler = Threshold_LR(optimizer, [1, 0.1, 0.09, 0.85, 0.08, 0.07], [learning_rate, 1e-4, 1e-5, 5e-6, 1e-6, 1e-7])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "start_epoch: int = 0\n",
    "if os.path.exists(full_model_path):\n",
    "    model = torch.load(full_model_path, map_location=device)\n",
    "    u_net.load_state_dict(model[\"model\"])\n",
    "    if 'ema_state' in model:\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and name in model['ema_state']:\n",
    "                ema.shadow[name] = model['ema_state'][name].clone()\n",
    "    if not restart_training:\n",
    "        optimizer.load_state_dict(model[\"optim\"])\n",
    "        scheduler.load_state_dict(model[\"scheduler\"])\n",
    "        start_epoch = model.get(\"epoch\", 0)\n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(u_net)} Parameters\")\n",
    "else: \n",
    "    logger.info(f\"Model {model_name} created with {count_parameters(u_net)} Parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion(model=u_net, \n",
    "                        noise_steps=conf[\"model\"].diffusion_timesteps, \n",
    "                        noise_schedule=\"cosine\", \n",
    "                        input_dim= [32, 1, 32, 32],\n",
    "                        ema = None,\n",
    "                        device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 19:47:36,596 - INFO - Training started on cuda\n"
     ]
    }
   ],
   "source": [
    "x = diffusion.train(epochs=epochs, \n",
    "                    data_loader=data_loader, \n",
    "                    loss_function=nn.MSELoss(),\n",
    "                    optimizer=optimizer, \n",
    "                    lr_scheduler=scheduler, \n",
    "                    gradient_accum=conf[\"model\"].gradient_accum,\n",
    "                    checkpoint_freq=checkpoint_freq, \n",
    "                    model_path=full_model_path, \n",
    "                    start_epoch=start_epoch,\n",
    "                    patience=100,\n",
    "                    ema_freq=0\n",
    "                )\n",
    "scatter_plot(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
