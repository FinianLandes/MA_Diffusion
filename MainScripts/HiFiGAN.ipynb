{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0896dd2a",
   "metadata": {},
   "source": [
    "# Main Script HiFiGAN\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7059a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.21)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.66.1)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from sqlalchemy>=1.4.2->optuna) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting plotly\n",
      "  Downloading plotly-6.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-1.43.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (23.2)\n",
      "Downloading plotly-6.1.2-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.43.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.7/362.7 kB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-1.43.0 plotly-6.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:56:57.327530: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-16 17:56:57.327588: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-16 17:56:57.328758: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-16 17:56:57.334814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-16 17:56:58.137395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "try: \n",
    "    import optuna, plotly\n",
    "except:\n",
    "    !pip install optuna\n",
    "    !pip install plotly\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.utils import weight_norm \n",
    "from torch.nn import utils\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchaudio.transforms as T\n",
    "import optuna, plotly\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging, librosa, itertools, tensorboard\n",
    "from typing import Sequence, Optional, Callable\n",
    "\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d7fbc",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12e407",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c14554",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = True #Set to true if using a remote Kernel changes the file structure\n",
    "model_name: str = \"HiFiGAN_v1\"\n",
    "training_data_name: str = \"training_full_mel\"\n",
    "training_label_name: str = \"training_full_wave\"\n",
    "full_model_path: str = path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, model_name + \".pth\"), remote_kernel)\n",
    "sw = SummaryWriter(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].model_path, 'logs'), remote_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7c208",
   "metadata": {},
   "source": [
    "Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c656f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level: int = LIGHT_DEBUG\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924858d",
   "metadata": {},
   "source": [
    "Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc9b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "n_training_samples: int = 2496 // 2\n",
    "batch_size: int = 16\n",
    "tensor_wave_dim: list = [batch_size, 1, 2**17] #B, C, H = Batch, channels, Time domain\n",
    "tensor_mel_dim: list = [batch_size, 96, 512]\n",
    "learning_rate: float = 1e-4\n",
    "b1, b2 = [0.7, 0.99]\n",
    "epochs: int = 300\n",
    "restart_training: bool = True\n",
    "checkpoint_freq: int = 5\n",
    "num_workers: int = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571b189",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c201a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:57:00,863 - LIGHT_DEBUG - Ndarray loaded from Data/training_full_mel.npy of shape: (6867, 96, 512)\n",
      "2025-06-16 17:57:02,183 - LIGHT_DEBUG - Ndarray loaded from Data/training_full_wave.npy of shape: (6867, 131072)\n"
     ]
    }
   ],
   "source": [
    "mel_data: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))\n",
    "audio_data: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_label_name + \".npy\"), remote_kernel))\n",
    "\n",
    "np.random.seed(50)\n",
    "indicies: ndarray = np.arange(mel_data.shape[0])\n",
    "np.random.shuffle(indicies)\n",
    "mel_data = mel_data[indicies]\n",
    "audio_data = audio_data[indicies]\n",
    "\n",
    "data_loader = create_dataloader(Audio_Data(mel_data[:n_training_samples], audio_data[:n_training_samples]), batch_size, num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a34ad",
   "metadata": {},
   "source": [
    "### Original Impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8037dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m, mean=0.0, std=0.01):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(mean, std)\n",
    "\n",
    "\n",
    "def apply_weight_norm(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        weight_norm(m)\n",
    "\n",
    "\n",
    "def get_padding(kernel_size, dilation=1):\n",
    "    return int((kernel_size*dilation - dilation)/2)\n",
    "\n",
    "\n",
    "class ResBlock1(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, dilation=(1, 3, 5)):\n",
    "        super(ResBlock1, self).__init__()\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=dilation[0],\n",
    "                                padding=get_padding(kernel_size, dilation[0]))),\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=dilation[1],\n",
    "                                padding=get_padding(kernel_size, dilation[1]))),\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=dilation[2],\n",
    "                                padding=get_padding(kernel_size, dilation[2])))\n",
    "        ])\n",
    "        self.convs1.apply(init_weights)\n",
    "\n",
    "        self.convs2 = nn.ModuleList([\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                                padding=get_padding(kernel_size, 1))),\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                                padding=get_padding(kernel_size, 1))),\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=1,\n",
    "                                padding=get_padding(kernel_size, 1)))\n",
    "        ])\n",
    "        self.convs2.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for c1, c2 in zip(self.convs1, self.convs2):\n",
    "            xt = F.leaky_relu(x, 0.1)\n",
    "            xt = c1(xt)\n",
    "            xt = F.leaky_relu(xt, 0.1)\n",
    "            xt = c2(xt)\n",
    "            x = xt + x\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        for l in self.convs1:\n",
    "            utils.remove_weight_norm(l)\n",
    "        for l in self.convs2:\n",
    "            utils.remove_weight_norm(l)\n",
    "\n",
    "\n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=3, dilation=(1, 3)):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=dilation[0],\n",
    "                                padding=get_padding(kernel_size, dilation[0]))),\n",
    "            weight_norm(nn.Conv1d(channels, channels, kernel_size, 1, dilation=dilation[1],\n",
    "                                padding=get_padding(kernel_size, dilation[1])))\n",
    "        ])\n",
    "        self.convs.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for c in self.convs:\n",
    "            xt = F.leaky_relu(x, 0.1)\n",
    "            xt = c(xt)\n",
    "            x = xt + x\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        for l in self.convs:\n",
    "            utils.remove_weight_norm(l)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_mel_channels: int, resblock_kernel_sizes: list[int], upsample_rates: list[int], upsample_initial_channel: int, upsample_kernel_sizes: list[int], resblock_dilation_sizes: list[int], resblock: int = 1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.num_kernels = len(resblock_kernel_sizes)\n",
    "        self.num_upsamples = len(upsample_rates)\n",
    "        self.conv_pre = weight_norm(nn.Conv1d(n_mel_channels, upsample_initial_channel, 7, 1, padding=3))\n",
    "        resblock = ResBlock1 if resblock == '1' else ResBlock2\n",
    "\n",
    "        self.ups = nn.ModuleList()\n",
    "        for i, (u, k) in enumerate(zip(upsample_rates, upsample_kernel_sizes)):\n",
    "            self.ups.append(weight_norm(\n",
    "                nn.ConvTranspose1d(upsample_initial_channel//(2**i), upsample_initial_channel//(2**(i+1)),\n",
    "                                k, u, padding=(k-u)//2)))\n",
    "\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        for i in range(len(self.ups)):\n",
    "            ch = upsample_initial_channel//(2**(i+1))\n",
    "            for j, (k, d) in enumerate(zip(resblock_kernel_sizes, resblock_dilation_sizes)):\n",
    "                self.resblocks.append(resblock(ch, k, d))\n",
    "\n",
    "        self.conv_post = weight_norm(nn.Conv1d(ch, 1, 7, 1, padding=3))\n",
    "        self.ups.apply(init_weights)\n",
    "        self.conv_post.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_pre(x)\n",
    "        for i in range(self.num_upsamples):\n",
    "            x = F.leaky_relu(x, 0.1)\n",
    "            x = self.ups[i](x)\n",
    "            xs = None\n",
    "            for j in range(self.num_kernels):\n",
    "                if xs is None:\n",
    "                    xs = self.resblocks[i*self.num_kernels+j](x)\n",
    "                else:\n",
    "                    xs += self.resblocks[i*self.num_kernels+j](x)\n",
    "            x = xs / self.num_kernels\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv_post(x)\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def remove_weight_norm(self):\n",
    "        logger.light_debug('Removing weight norm...')\n",
    "        for l in self.ups:\n",
    "            utils.remove_weight_norm(l)\n",
    "        for l in self.resblocks:\n",
    "            l.remove_weight_norm()\n",
    "        utils.remove_weight_norm(self.conv_pre)\n",
    "        utils.remove_weight_norm(self.conv_post)\n",
    "\n",
    "\n",
    "class DiscriminatorP(nn.Module):\n",
    "    def __init__(self, period, kernel_size=5, stride=3, use_spectral_norm=False):\n",
    "        super(DiscriminatorP, self).__init__()\n",
    "        self.period = period\n",
    "        norm_f = weight_norm if use_spectral_norm == False else utils.spectral_norm\n",
    "        self.convs = nn.ModuleList([\n",
    "            norm_f(nn.Conv2d(1, 32, (kernel_size, 1), (stride, 1), padding=(get_padding(5, 1), 0))),\n",
    "            norm_f(nn.Conv2d(32, 128, (kernel_size, 1), (stride, 1), padding=(get_padding(5, 1), 0))),\n",
    "            norm_f(nn.Conv2d(128, 512, (kernel_size, 1), (stride, 1), padding=(get_padding(5, 1), 0))),\n",
    "            norm_f(nn.Conv2d(512, 1024, (kernel_size, 1), (stride, 1), padding=(get_padding(5, 1), 0))),\n",
    "            norm_f(nn.Conv2d(1024, 1024, (kernel_size, 1), 1, padding=(2, 0))),\n",
    "        ])\n",
    "        self.conv_post = norm_f(nn.Conv2d(1024, 1, (3, 1), 1, padding=(1, 0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fmap = []\n",
    "\n",
    "        # 1d to 2d\n",
    "        b, c, t = x.shape\n",
    "        if t % self.period != 0: # pad first\n",
    "            n_pad = self.period - (t % self.period)\n",
    "            x = F.pad(x, (0, n_pad), \"reflect\")\n",
    "            t = t + n_pad\n",
    "        x = x.view(b, c, t // self.period, self.period)\n",
    "\n",
    "        for l in self.convs:\n",
    "            x = l(x)\n",
    "            x = F.leaky_relu(x, 0.1)\n",
    "            fmap.append(x)\n",
    "        x = self.conv_post(x)\n",
    "        fmap.append(x)\n",
    "        x = torch.flatten(x, 1, -1)\n",
    "\n",
    "        return x, fmap\n",
    "\n",
    "\n",
    "class MultiPeriodDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiPeriodDiscriminator, self).__init__()\n",
    "        self.discriminators = nn.ModuleList([\n",
    "            DiscriminatorP(2),\n",
    "            DiscriminatorP(3),\n",
    "            DiscriminatorP(5),\n",
    "            DiscriminatorP(7),\n",
    "            DiscriminatorP(11),\n",
    "        ])\n",
    "\n",
    "    def forward(self, y, y_hat):\n",
    "        y_d_rs = []\n",
    "        y_d_gs = []\n",
    "        fmap_rs = []\n",
    "        fmap_gs = []\n",
    "        for i, d in enumerate(self.discriminators):\n",
    "            y_d_r, fmap_r = d(y)\n",
    "            y_d_g, fmap_g = d(y_hat)\n",
    "            y_d_rs.append(y_d_r)\n",
    "            fmap_rs.append(fmap_r)\n",
    "            y_d_gs.append(y_d_g)\n",
    "            fmap_gs.append(fmap_g)\n",
    "\n",
    "        return y_d_rs, y_d_gs, fmap_rs, fmap_gs\n",
    "\n",
    "\n",
    "class DiscriminatorS(torch.nn.Module):\n",
    "    def __init__(self, use_spectral_norm=False):\n",
    "        super(DiscriminatorS, self).__init__()\n",
    "        norm_f = weight_norm if use_spectral_norm == False else utils.spectral_norm\n",
    "        self.convs = nn.ModuleList([\n",
    "            norm_f(nn.Conv1d(1, 128, 15, 1, padding=7)),\n",
    "            norm_f(nn.Conv1d(128, 128, 41, 2, groups=4, padding=20)),\n",
    "            norm_f(nn.Conv1d(128, 256, 41, 2, groups=16, padding=20)),\n",
    "            norm_f(nn.Conv1d(256, 512, 41, 4, groups=16, padding=20)),\n",
    "            norm_f(nn.Conv1d(512, 1024, 41, 4, groups=16, padding=20)),\n",
    "            norm_f(nn.Conv1d(1024, 1024, 41, 1, groups=16, padding=20)),\n",
    "            norm_f(nn.Conv1d(1024, 1024, 5, 1, padding=2)),\n",
    "        ])\n",
    "        self.conv_post = norm_f(nn.Conv1d(1024, 1, 3, 1, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fmap = []\n",
    "        for l in self.convs:\n",
    "            x = l(x)\n",
    "            x = F.leaky_relu(x, 0.1)\n",
    "            fmap.append(x)\n",
    "        x = self.conv_post(x)\n",
    "        fmap.append(x)\n",
    "        x = torch.flatten(x, 1, -1)\n",
    "\n",
    "        return x, fmap\n",
    "\n",
    "\n",
    "class MultiScaleDiscriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleDiscriminator, self).__init__()\n",
    "        self.discriminators = nn.ModuleList([\n",
    "            DiscriminatorS(use_spectral_norm=True),\n",
    "            DiscriminatorS(),\n",
    "            DiscriminatorS(),\n",
    "        ])\n",
    "        self.meanpools = nn.ModuleList([\n",
    "            nn.AvgPool1d(4, 2, padding=2),\n",
    "            nn.AvgPool1d(4, 2, padding=2)\n",
    "        ])\n",
    "\n",
    "    def forward(self, y, y_hat):\n",
    "        y_d_rs = []\n",
    "        y_d_gs = []\n",
    "        fmap_rs = []\n",
    "        fmap_gs = []\n",
    "        for i, d in enumerate(self.discriminators):\n",
    "            if i != 0:\n",
    "                y = self.meanpools[i-1](y)\n",
    "                y_hat = self.meanpools[i-1](y_hat)\n",
    "            y_d_r, fmap_r = d(y)\n",
    "            y_d_g, fmap_g = d(y_hat)\n",
    "            y_d_rs.append(y_d_r)\n",
    "            fmap_rs.append(fmap_r)\n",
    "            y_d_gs.append(y_d_g)\n",
    "            fmap_gs.append(fmap_g)\n",
    "\n",
    "        return y_d_rs, y_d_gs, fmap_rs, fmap_gs\n",
    "\n",
    "\n",
    "def feature_loss(fmap_r, fmap_g):\n",
    "    loss = 0\n",
    "    for dr, dg in zip(fmap_r, fmap_g):\n",
    "        for rl, gl in zip(dr, dg):\n",
    "            loss += torch.mean(torch.abs(rl - gl))\n",
    "\n",
    "    return loss*2\n",
    "\n",
    "\n",
    "def discriminator_loss(disc_real_outputs, disc_generated_outputs):\n",
    "    loss = 0\n",
    "    r_losses = []\n",
    "    g_losses = []\n",
    "    for dr, dg in zip(disc_real_outputs, disc_generated_outputs):\n",
    "        r_loss = torch.mean((1-dr)**2)\n",
    "        g_loss = torch.mean(dg**2)\n",
    "        loss += (r_loss + g_loss)\n",
    "        r_losses.append(r_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "\n",
    "    return loss, r_losses, g_losses\n",
    "\n",
    "\n",
    "def generator_loss(disc_outputs):\n",
    "    loss = 0\n",
    "    gen_losses = []\n",
    "    for dg in disc_outputs:\n",
    "        l = torch.mean((1-dg)**2)\n",
    "        gen_losses.append(l)\n",
    "        loss += l\n",
    "\n",
    "    return loss, gen_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6de654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(\n",
    "                    n_mel_channels=96,\n",
    "                    upsample_rates=[8,8,2,2],\n",
    "                    upsample_kernel_sizes=[16,16,4,4],\n",
    "                    upsample_initial_channel=512,\n",
    "                    resblock_kernel_sizes=[3,7,11],\n",
    "                    resblock_dilation_sizes=[[1,3,5], [1,3,5], [1,3,5]],\n",
    "                    resblock=1\n",
    "                ).to(device)\n",
    "mpd = MultiPeriodDiscriminator().to(device)\n",
    "msd = MultiScaleDiscriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7197e270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:57:05,968 - INFO - Model HiFiGAN_v1 loaded with ~6.671M G and ~41.10M, ~29.61M D Parameters\n"
     ]
    }
   ],
   "source": [
    "optim_g = torch.optim.AdamW(generator.parameters(), learning_rate, betas=[b1, b2])\n",
    "optim_d = torch.optim.AdamW(itertools.chain(msd.parameters(), mpd.parameters()),\n",
    "                                learning_rate, betas=[b1, b2])\n",
    "gen_lr_scheduler = optim.lr_scheduler.ExponentialLR(optim_g, gamma=0.999)\n",
    "disc_lr_scheduler = optim.lr_scheduler.ExponentialLR(optim_d, gamma=0.999)\n",
    "start_epoch: int = 0\n",
    "if os.path.exists(full_model_path):\n",
    "    model = torch.load(full_model_path, map_location=device)\n",
    "    generator.load_state_dict(model[\"generator\"])\n",
    "    msd.load_state_dict(model[\"msd\"])\n",
    "    mpd.load_state_dict(model[\"mpd\"])\n",
    "    if not restart_training:\n",
    "        optim_g.load_state_dict(model[\"optim_g\"])\n",
    "        optim_d.load_state_dict(model[\"optim_d\"])\n",
    "        start_epoch = model.get(\"epoch\", 0)\n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(generator)} G and {count_parameters(mpd)}, {count_parameters(msd)} D Parameters\")\n",
    "else: \n",
    "    logger.info(f\"Model {model_name} loaded with {count_parameters(generator)} G and {count_parameters(mpd)}, {count_parameters(msd)} D Parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267dffe",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8620c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_model() -> nn.Module:\n",
    "    generator = Generator(\n",
    "                    n_mel_channels=96,\n",
    "                    upsample_rates=[8,8,2,2],\n",
    "                    upsample_kernel_sizes=[16,16,4,4],\n",
    "                    upsample_initial_channel=512,\n",
    "                    resblock_kernel_sizes=[3,7,11],\n",
    "                    resblock_dilation_sizes=[[1,3,5], [1,3,5], [1,3,5]],\n",
    "                    resblock=1\n",
    "                ).to(device)\n",
    "    mpd = MultiPeriodDiscriminator().to(device)\n",
    "    msd = MultiScaleDiscriminator().to(device)\n",
    "    return generator, mpd, msd\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    b1 = trial.suggest_float(\"b1\", 0.4, 0.99)\n",
    "    b2 = trial.suggest_float(\"b2\", 0.4, 0.999)\n",
    "    lr_decay = trial.suggest_float(\"lr_decay\", 0.7, 0.99999)\n",
    "    generator, mpd, msd = static_model()\n",
    "    optim_g = torch.optim.AdamW(generator.parameters(), lr, betas=[b1, b2])\n",
    "    optim_d = torch.optim.AdamW(itertools.chain(msd.parameters(), mpd.parameters()),\n",
    "                                    lr, betas=[b1, b2])\n",
    "    gen_lr_scheduler = optim.lr_scheduler.ExponentialLR(optim_g, gamma=lr_decay)\n",
    "    disc_lr_scheduler = optim.lr_scheduler.ExponentialLR(optim_d, gamma=lr_decay)\n",
    "\n",
    "    \n",
    "    n_epochs = 10\n",
    "    best_reconst_loss: float = float('inf')\n",
    "    generator.train()\n",
    "    mpd.train()\n",
    "    msd.train()\n",
    "    for e in range(0, n_epochs):\n",
    "        total_reconst_loss: float = 0\n",
    "\n",
    "        for b_idx, (mel, audio) in enumerate(data_loader):\n",
    "            mel, audio = mel.to(device), audio.to(device).unsqueeze(1)\n",
    "            with torch.autocast(device_type=device):\n",
    "                generated_audio = generator(mel)\n",
    "\n",
    "            generated_mel = T.MelSpectrogram(sample_rate = 32000, n_fft=1023, hop_length=256, n_mels=96, f_min=30).to(device)(generated_audio.squeeze(1))\n",
    "            optim_d.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device):\n",
    "                real_mpd_scores, fake_mpd_scores, _, _ = mpd(audio, generated_audio.detach())\n",
    "            loss_d_s, mpd_loss_real, mpd_loss_fake = discriminator_loss(real_mpd_scores, fake_mpd_scores)\n",
    "            \n",
    "            with torch.autocast(device_type=device):\n",
    "                real_msd_scores, fake_msd_scores, _, _ = msd(audio, generated_audio.detach())\n",
    "            loss_d_f, msd_loss_real, msd_loss_fake = discriminator_loss(real_msd_scores, fake_msd_scores)\n",
    "\n",
    "            total_disc_loss: Tensor = loss_d_s + loss_d_f\n",
    "\n",
    "            total_disc_loss.backward()\n",
    "            optim_d.step()\n",
    "\n",
    "            optim_g.zero_grad()\n",
    "\n",
    "            mel_loss = F.l1_loss(mel, generated_mel) * 45\n",
    "\n",
    "            with torch.autocast(device_type=device):\n",
    "                real_mpd_scores, fake_mpd_scores, real_mpd_features, fake_mpd_features = mpd(audio, generated_audio)\n",
    "                real_msd_scores, fake_msd_scores, real_msd_features, fake_msd_features = msd(audio, generated_audio)\n",
    "            \n",
    "            mpd_feature_loss = feature_loss(real_mpd_features, fake_mpd_features)\n",
    "            msd_feature_loss = feature_loss(real_msd_features, fake_msd_features)\n",
    "            mpd_gen_loss, _ = generator_loss(fake_mpd_scores)\n",
    "            msd_gen_loss, _ = generator_loss(fake_msd_scores)\n",
    "            \n",
    "            total_reconst_loss += (F.l1_loss(audio, generated_audio) + mel_loss / 45) / 2\n",
    "\n",
    "            total_gen_loss = mpd_gen_loss + msd_gen_loss + mpd_feature_loss + msd_feature_loss + mel_loss\n",
    "\n",
    "            total_gen_loss.backward()\n",
    "            optim_g.step()\n",
    "\n",
    "            avg_reconst_loss = total_reconst_loss / len(data_loader)\n",
    "\n",
    "\n",
    "            gen_lr_scheduler.step()\n",
    "            disc_lr_scheduler.step()\n",
    "\n",
    "    \n",
    "        if avg_reconst_loss < best_reconst_loss:\n",
    "            best_reconst_loss = avg_reconst_loss\n",
    "        trial.report(avg_reconst_loss, e)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    return best_reconst_loss\n",
    "\n",
    "def run_optim(n_trials: int, name: str =\"main_study_wave\") -> None:\n",
    "    study = optuna.create_study(direction=\"minimize\", pruner=optuna.pruners.MedianPruner(),study_name=name)\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    logger.info(\"Finished Study\")\n",
    "    logger.info(f\"Best trial: {study.best_trial} with value: {study.best_trial.value} using params:\")\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        logger.info(f\"{key}:{val}\")\n",
    "    \n",
    "    logger.info(\"Param importance:\")\n",
    "    for param, importance in get_param_importances(study).items():\n",
    "            logger.info(f\"{param}: {importance:.4f}\")\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-16 17:57:06,176] A new study created in memory with name: main_study\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "[I 2025-06-16 18:19:40,773] Trial 0 finished with value: 0.23749111592769623 and parameters: {'lr': 0.0006364028564452524, 'b1': 0.7872070788505228, 'b2': 0.5387522714858821, 'lr_decay': 0.8797010728452869}. Best is trial 0 with value: 0.23749111592769623.\n",
      "[I 2025-06-16 18:42:15,557] Trial 1 finished with value: 0.2389201670885086 and parameters: {'lr': 0.0006317571936581328, 'b1': 0.9317838884335691, 'b2': 0.6985585219527081, 'lr_decay': 0.9189079868516059}. Best is trial 0 with value: 0.23749111592769623.\n",
      "[I 2025-06-16 19:04:53,468] Trial 2 finished with value: 0.23809592425823212 and parameters: {'lr': 0.00015222819211399175, 'b1': 0.8835259616332495, 'b2': 0.6759253199716412, 'lr_decay': 0.7871656983646544}. Best is trial 0 with value: 0.23749111592769623.\n",
      "[I 2025-06-16 19:27:31,760] Trial 3 finished with value: 0.23827217519283295 and parameters: {'lr': 0.00035883244083511793, 'b1': 0.6676474017690415, 'b2': 0.8710038483127349, 'lr_decay': 0.7170858922185632}. Best is trial 0 with value: 0.23749111592769623.\n"
     ]
    }
   ],
   "source": [
    "run_optim(25, \"main_study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:40:23,964 - INFO - Training started on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:40:25,000 - LIGHT_DEBUG - Batch 001/078 D/G Loss: 1.570 123.769"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m total_reconst_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39ml1_loss(audio, generated_audio)\n\u001b[1;32m     51\u001b[0m total_gen_loss \u001b[38;5;241m=\u001b[39m mpd_gen_loss \u001b[38;5;241m+\u001b[39m msd_gen_loss \u001b[38;5;241m+\u001b[39m mpd_feature_loss \u001b[38;5;241m+\u001b[39m msd_feature_loss \u001b[38;5;241m+\u001b[39m mel_loss\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtotal_gen_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m optim_g\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel() \u001b[38;5;241m==\u001b[39m LIGHT_DEBUG:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info(f\"Training started on {device}\")\n",
    "loss_d_list: list = []\n",
    "loss_g_list: list = []\n",
    "total_time: float = 0.0\n",
    "\n",
    "generator.train()\n",
    "mpd.train()\n",
    "msd.train()\n",
    "for e in range(0, epochs):\n",
    "    total_d_loss: float = 0\n",
    "    total_g_loss: float = 0\n",
    "    total_reconst_loss: float = 0\n",
    "    start_time: float = time.time()\n",
    "\n",
    "    for b_idx, (mel, audio) in enumerate(data_loader):\n",
    "            mel, audio = mel.to(device), audio.to(device).unsqueeze(1)\n",
    "            with torch.autocast(device_type=device):\n",
    "                generated_audio = generator(mel)\n",
    "\n",
    "            generated_mel = T.MelSpectrogram(sample_rate = 32000, n_fft=1023, hop_length=256, n_mels=96, f_min=30).to(device)(generated_audio.squeeze(1))\n",
    "            optim_d.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device):\n",
    "                real_mpd_scores, fake_mpd_scores, _, _ = mpd(audio, generated_audio.detach())\n",
    "            loss_d_s, mpd_loss_real, mpd_loss_fake = discriminator_loss(real_mpd_scores, fake_mpd_scores)\n",
    "            \n",
    "            with torch.autocast(device_type=device):\n",
    "                real_msd_scores, fake_msd_scores, _, _ = msd(audio, generated_audio.detach())\n",
    "            loss_d_f, msd_loss_real, msd_loss_fake = discriminator_loss(real_msd_scores, fake_msd_scores)\n",
    "\n",
    "            total_disc_loss: Tensor = loss_d_s + loss_d_f\n",
    "\n",
    "            total_disc_loss.backward()\n",
    "            optim_d.step()\n",
    "\n",
    "            optim_g.zero_grad()\n",
    "\n",
    "            mel_loss = F.l1_loss(mel, generated_mel) * 45\n",
    "\n",
    "            with torch.autocast(device_type=device):\n",
    "                real_mpd_scores, fake_mpd_scores, real_mpd_features, fake_mpd_features = mpd(audio, generated_audio)\n",
    "                real_msd_scores, fake_msd_scores, real_msd_features, fake_msd_features = msd(audio, generated_audio)\n",
    "            \n",
    "            mpd_feature_loss = feature_loss(real_mpd_features, fake_mpd_features)\n",
    "            msd_feature_loss = feature_loss(real_msd_features, fake_msd_features)\n",
    "            mpd_gen_loss, _ = generator_loss(fake_mpd_scores)\n",
    "            msd_gen_loss, _ = generator_loss(fake_msd_scores)\n",
    "            \n",
    "            total_reconst_loss += F.l1_loss(audio, generated_audio)\n",
    "\n",
    "            total_gen_loss = mpd_gen_loss + msd_gen_loss + mpd_feature_loss + msd_feature_loss + mel_loss\n",
    "\n",
    "            total_gen_loss.backward()\n",
    "            optim_g.step()\n",
    "\n",
    "            if logger.getEffectiveLevel() == LIGHT_DEBUG:\n",
    "                current_batch = b_idx + 1\n",
    "                print(f\"\\r{time.strftime('%Y-%m-%d %H:%M:%S')},000 - LIGHT_DEBUG - Batch {current_batch:03d}/{len(data_loader):03d} D/G Loss: {total_disc_loss.item():.3f} {total_gen_loss.item():.3f}\", end='', flush=True)\n",
    "    else:\n",
    "        if logger.getEffectiveLevel() == LIGHT_DEBUG:\n",
    "            print(flush=True)\n",
    "\n",
    "        avg_d_loss = total_disc_loss / len(data_loader)\n",
    "        avg_g_loss = total_gen_loss / len(data_loader)\n",
    "        avg_reconst_loss = total_reconst_loss / len(data_loader)\n",
    "        loss_d_list.append(avg_d_loss)\n",
    "        loss_g_list.append(avg_g_loss)\n",
    "        if gen_lr_scheduler is not None:\n",
    "            gen_lr_scheduler.step()\n",
    "        if disc_lr_scheduler is not None:\n",
    "            disc_lr_scheduler.step()\n",
    "\n",
    "        sw.add_scalar(\"training/gen_loss\", avg_g_loss, e)\n",
    "        sw.add_scalar(\"training/disc_loss\", avg_d_loss, e)\n",
    "        sw.add_scalar(\"training/reconstr_loss\", avg_reconst_loss, e)\n",
    "        sw.add_scalar(\"training/lr\", optim_g.param_groups[0][\"lr\"], e)\n",
    "        sw.flush()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        total_time += epoch_time\n",
    "        remaining_time = int((total_time / (e + 1)) * (epochs - e - 1))\n",
    "\n",
    "        logger.info(f\"Epoch {e + 1:03d}: Avg. D/G Loss: {avg_d_loss:.4e}, {avg_g_loss:.4e} Avg. reconst. Loss: {avg_reconst_loss:.4e} Remaining Time: {remaining_time // 3600:02d}h {(remaining_time % 3600) // 60:02d}min {round(remaining_time % 60):02d}s LR: {optim_d.param_groups[0]['lr']:.5e} \")\n",
    "        \n",
    "        if checkpoint_freq > 0 and (e + 1) % checkpoint_freq == 0:\n",
    "            checkpoint_path: str = f\"{full_model_path[:-4]}_epoch_{e + 1:03d}.pth\"\n",
    "            torch.save({\"generator\": generator.state_dict(), \"msd\": msd.state_dict(), \"mpd\": mpd.state_dict(), \"optim_g\": optim_g.state_dict(), \"optim_d\": optim_d.state_dict() , \"epoch\": e + 1}, checkpoint_path)\n",
    "            if e + 1 != checkpoint_freq:\n",
    "                last_path: str = f\"{full_model_path[:-4]}_epoch_{(e + 1) - checkpoint_freq:03d}.pth\"\n",
    "                del_if_exists(last_path)\n",
    "            logger.light_debug(f\"Checkpoint saved model to {checkpoint_path}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "torch.save({\"generator\": generator.state_dict(), \"msd\": msd.state_dict(), \"mpd\": mpd.state_dict(), \"optim_g\": optim_g.state_dict(), \"optim_d\": optim_d.state_dict() , \"epoch\": e + 1}, full_model_path)\n",
    "\n",
    "logger.light_debug(f\"Saved model to {full_model_path}\")\n",
    "\n",
    "if checkpoint_freq > 0:\n",
    "    checkpoint_path: str = f\"{full_model_path[:-4]}_epoch_{e + 1 - ((e + 1) % checkpoint_freq):03d}.pth\"\n",
    "    del_if_exists(checkpoint_path)\n",
    "\n",
    "scatter_plot(loss_d_list)\n",
    "scatter_plot(loss_g_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50424b99",
   "metadata": {},
   "source": [
    "### Convert to wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8a83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:39:08,196 - LIGHT_DEBUG - Normalized to range: [-0.99999,0.99999]\n",
      "2025-06-16 17:39:08,210 - LIGHT_DEBUG - Saved file to:test3.wav\n"
     ]
    }
   ],
   "source": [
    "file_idx: int = 4000\n",
    "with torch.no_grad():\n",
    "    generated_wave = generator(torch.tensor(mel_data[file_idx]).unsqueeze(0).to(device))\n",
    "save_audio_file(generated_wave.cpu().numpy()[0,0], \"test3.wav\", 32000)\n",
    "#save_audio_file(librosa.feature.inverse.mel_to_audio(mel_data[file_idx], n_fft=1023, hop_length=256, sr=32000), \"test_gl.wav\", 32000)\n",
    "#save_audio_file(audio_data[file_idx], \"test_real.wav\", 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b224011",
   "metadata": {},
   "outputs": [],
   "source": [
    "spect = load_spectrogram(\"spect.npz\")\n",
    "with torch.no_grad():\n",
    "    generated_wave = generator(torch.tensor(spect).unsqueeze(0).to(device))\n",
    "save_audio_file(generated_wave.cpu().numpy()[0,0], \"muGen_out2.wav\", 32000)\n",
    "save_audio_file(librosa.feature.inverse.mel_to_audio(spect, n_fft=1023, hop_length=256, sr=32000), \"muGen_out1_gl.wav\", 32000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
