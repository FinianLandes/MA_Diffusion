{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395c3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import librosa\n",
    "except:\n",
    "    !pip install librosa\n",
    "\n",
    "#Set Dir \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "from torchaudio.prototype.pipelines import VGGISH\n",
    "import torchaudio\n",
    "# Utils\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import logging\n",
    "from typing import Sequence, Optional, Callable\n",
    "\n",
    "\n",
    "# Base Scripts\n",
    "from Libraries.Utils import *\n",
    "from MainScripts.Conf import conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b5d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_kernel: bool = False #Set to true if using a remote Kernel changes the file structure\n",
    "training_data_name: str = \"training_full_wave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75262c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_level: int = LIGHT_DEBUG\n",
    "logging.basicConfig(level=logging_level, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed075526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:44:44,758 - LIGHT_DEBUG - Ndarray loaded from ../Data/training_full_wave.npy of shape: (5906, 147200)\n"
     ]
    }
   ],
   "source": [
    "file: ndarray = load_training_data(path_to_remote_path(\"{}/{}\".format(conf[\"paths\"].data_path, training_data_name + \".npy\"), remote_kernel))[:, :2**17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38ef0668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 15:44:46,500 - INFO - The local file (C:\\Users\\finia\\.cache\\torch\\hub\\torchaudio\\models\\vggish.pt) exists. Skipping the download.\n"
     ]
    }
   ],
   "source": [
    "input_sr = VGGISH.sample_rate\n",
    "input_proc = VGGISH.get_input_processor()\n",
    "model = VGGISH.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1207127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 96, 64])\n",
      "tensor([[0.0000, 0.0400, 0.2845, 0.0000, 0.3216, 0.0000, 0.0000, 0.1933, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.8301, 0.0000, 0.0000, 0.0000, 0.3121, 0.0823,\n",
      "         0.0000, 0.0000, 0.0907, 0.0000, 0.0000, 0.0000, 0.4028, 0.1027, 0.0326,\n",
      "         0.0000, 0.1104, 0.0000, 0.0000, 0.0931, 0.0431, 0.4463, 0.1814, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0571, 0.0000, 0.0000, 0.0000, 0.1214,\n",
      "         0.0000, 0.1193, 0.3394, 0.0141, 0.4284, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.3775, 0.0000, 0.2696, 0.4558, 0.2623, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2607, 0.0000, 0.0500, 0.4877, 0.2032, 0.0000, 0.0896, 0.0228,\n",
      "         0.1568, 0.0000, 0.0987, 0.0000, 0.0000, 0.3317, 0.3539, 0.7980, 0.0000,\n",
      "         0.4121, 0.7023, 0.0000, 0.0645, 0.2822, 0.0678, 0.7346, 0.0000, 0.3024,\n",
      "         0.0000, 0.3742, 0.0000, 0.8792, 0.0038, 0.3753, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4712, 0.0097, 0.0912, 0.0000, 0.0000, 0.3182, 0.0000,\n",
      "         0.4748, 0.0000, 0.0237, 0.0000, 0.2090, 0.0000, 0.0000, 0.0082, 0.0633,\n",
      "         0.1791, 0.0000, 0.0528, 0.0170, 0.0000, 0.0000, 0.0000, 0.0164, 0.0000,\n",
      "         0.0495, 0.0681]], grad_fn=<UnsqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "waveform = torchaudio.functional.resample(torch.tensor(file[40]), 32000, input_sr)\n",
    "pre_proc = input_proc(waveform)\n",
    "print(pre_proc.shape)\n",
    "mono_out = model(pre_proc)\n",
    "mean_val = torch.mean(mono_out, dim=0).unsqueeze(0)\n",
    "print(mean_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
